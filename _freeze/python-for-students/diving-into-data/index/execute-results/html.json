{
  "hash": "a86117add01b72e5fec819239342e384",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Diving Deeper Into Data\nsubtitle: using pandas and matplotlib\njupyter: python3\norder: 10\nformat:\n  html:\n    code-fold: false\n---\n\n\n\nBy now we have covered a few basics - we learnt about different data types including lists, sequences and dictionaries, and we learnt how to use loops and conditions to manipulate data. We also learnt how to define simple functions, and how to load external modules to extend the functionality of Python.\n\nLet us now dive a bit deeper into data, how to manipulate it, and how to use it to answer questions and get some insights. We will use the `pandas` library to work with data, and the `matplotlib` library to visualize it.\n\n:::{.callout-note}\n## Learning Objectives\n\nThe `pandas` library is a powerful, yet large library that is used for data manipulation and analysis. We will only scratch the surface of what it can do in this book. As you progress, you can and should refer to the [official documentation](https://pandas.pydata.org//docs/user_guide/10min.html) to learn more, and to hone your skills.\n:::\n\n\n## Data and datasets\n\nYou will likely have come accross some data before that you had to work with, perhaps in Excel. There are also lots of different public datasets available online that you can use to practice your data analysis skills. A great resource for this is [Kaggle](https://www.kaggle.com/datasets), where you can find datasets on a wide range of topics.\n\nFor this section, we will use a public dataset from Kaggle which includes earthquake data from around the world. You can download the dataset from [this link](https://www.kaggle.com/datasets/usgs/earthquake-database). The dataset is in CSV format, which by now you should be familiar with and can load.\n\n### Downloading the dataset\n\nThere are several ways to get a public dataset into your computer - you can download it directly from the website, or you can use the `kaggle` command line tool to download it. Because we are practicing some programming skills, we will use the command line tool to download the dataset.\n\nTo install it you can use `conda`, as follows:\n\n```bash\nconda install -c conda-forge kaggle\n```\n\nOnce you have installed the tool, you need to create a profile in Kaggle and create an API key. Instead of rewriting the instructions here, just follow the excellent instructions by Christian Mills in [this blog post](https://christianjmills.com/posts/kaggle-obtain-api-key-tutorial//).\n\nOnce you have your API key, you can download the dataset using the following command:\n\n```bash\nkaggle datasets download usgs/earthquake-database\n```\n\n:::{.callout-note}\n## About Downloading Datasets\n:class: tip, dropdown\nThere are other ways to download the dataset, such as using packages like [Kagglehub](https://anaconda.org/anaconda/kagglehub), or [mlcroissant](https://anaconda.org/conda-forge/mlcroissant). But for now we will use the command line tool as the other approaches are programmatic.\n:::\n\nYour new dataset will be in a compressed zip file named `earthquake-database.zip` ready to be explored!\n\n## Loading and working with data\n\nPandas can unpack zip files directly, let us see how to do it.\n\n::: {#c47bca2e .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Read the CSV directly from the zip\nearthquakes = pd.read_csv('earthquake-database.zip', compression='zip')\n\nearthquakes.head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/02/1965</td>\n      <td>13:44:18</td>\n      <td>19.246</td>\n      <td>145.616</td>\n      <td>Earthquake</td>\n      <td>131.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860706</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/04/1965</td>\n      <td>11:29:49</td>\n      <td>1.863</td>\n      <td>127.352</td>\n      <td>Earthquake</td>\n      <td>80.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860737</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/05/1965</td>\n      <td>18:05:58</td>\n      <td>-20.579</td>\n      <td>-173.972</td>\n      <td>Earthquake</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.2</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860762</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/08/1965</td>\n      <td>18:49:43</td>\n      <td>-59.076</td>\n      <td>-23.557</td>\n      <td>Earthquake</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860856</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/09/1965</td>\n      <td>13:32:50</td>\n      <td>11.938</td>\n      <td>126.427</td>\n      <td>Earthquake</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860890</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01/10/1965</td>\n      <td>13:36:32</td>\n      <td>-13.405</td>\n      <td>166.629</td>\n      <td>Earthquake</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.7</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860922</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>01/12/1965</td>\n      <td>13:32:25</td>\n      <td>27.357</td>\n      <td>87.867</td>\n      <td>Earthquake</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.9</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861007</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>01/15/1965</td>\n      <td>23:17:42</td>\n      <td>-13.309</td>\n      <td>166.212</td>\n      <td>Earthquake</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861111</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01/16/1965</td>\n      <td>11:32:37</td>\n      <td>-56.452</td>\n      <td>-27.043</td>\n      <td>Earthquake</td>\n      <td>95.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEMSUP861125</td>\n      <td>ISCGEMSUP</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01/17/1965</td>\n      <td>10:43:17</td>\n      <td>-24.563</td>\n      <td>178.487</td>\n      <td>Earthquake</td>\n      <td>565.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861148</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 21 columns</p>\n</div>\n```\n:::\n:::\n\n\nThere's a few new things there. We loaded the file with `read_csv` as we encountered before, but this time we passed the `compression` argument to specify that the file is compressed. We also used the `head` method to show the first 10 rows of the dataframe. This is a very useful method to quickly check the contents of a dataset.\n\nPandas offers a few other methods to quickly check the contents of a dataframe, such as `info` and `describe`. Let us see how they work.\n\n::: {#4b6253cf .cell execution_count=3}\n``` {.python .cell-code}\nearthquakes.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Error</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23412.000000</td>\n      <td>23412.000000</td>\n      <td>23412.000000</td>\n      <td>4461.000000</td>\n      <td>7097.000000</td>\n      <td>23412.000000</td>\n      <td>327.000000</td>\n      <td>2564.000000</td>\n      <td>7299.000000</td>\n      <td>1604.000000</td>\n      <td>1156.000000</td>\n      <td>17352.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.679033</td>\n      <td>39.639961</td>\n      <td>70.767911</td>\n      <td>4.993115</td>\n      <td>275.364098</td>\n      <td>5.882531</td>\n      <td>0.071820</td>\n      <td>48.944618</td>\n      <td>44.163532</td>\n      <td>3.992660</td>\n      <td>7.662759</td>\n      <td>1.022784</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>30.113183</td>\n      <td>125.511959</td>\n      <td>122.651898</td>\n      <td>4.875184</td>\n      <td>162.141631</td>\n      <td>0.423066</td>\n      <td>0.051466</td>\n      <td>62.943106</td>\n      <td>32.141486</td>\n      <td>5.377262</td>\n      <td>10.430396</td>\n      <td>0.188545</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-77.080000</td>\n      <td>-179.997000</td>\n      <td>-1.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004505</td>\n      <td>0.085000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-18.653000</td>\n      <td>-76.349750</td>\n      <td>14.522500</td>\n      <td>1.800000</td>\n      <td>146.000000</td>\n      <td>5.600000</td>\n      <td>0.046000</td>\n      <td>10.000000</td>\n      <td>24.100000</td>\n      <td>0.968750</td>\n      <td>5.300000</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-3.568500</td>\n      <td>103.982000</td>\n      <td>33.000000</td>\n      <td>3.500000</td>\n      <td>255.000000</td>\n      <td>5.700000</td>\n      <td>0.059000</td>\n      <td>28.000000</td>\n      <td>36.000000</td>\n      <td>2.319500</td>\n      <td>6.700000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>26.190750</td>\n      <td>145.026250</td>\n      <td>54.000000</td>\n      <td>6.300000</td>\n      <td>384.000000</td>\n      <td>6.000000</td>\n      <td>0.075500</td>\n      <td>66.000000</td>\n      <td>54.000000</td>\n      <td>4.724500</td>\n      <td>8.100000</td>\n      <td>1.130000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>86.005000</td>\n      <td>179.998000</td>\n      <td>700.000000</td>\n      <td>91.295000</td>\n      <td>934.000000</td>\n      <td>9.100000</td>\n      <td>0.410000</td>\n      <td>821.000000</td>\n      <td>360.000000</td>\n      <td>37.874000</td>\n      <td>99.000000</td>\n      <td>3.440000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe `describe` method gives us a summary of the numerical columns in the dataframe. It shows the count of non-null values, the mean, standard deviation, minimum, maximum, and the quartiles of the data. This is a very useful method to quickly get an idea of the distribution of the data.\n\n::: {#158b1da9 .cell execution_count=4}\n``` {.python .cell-code}\nearthquakes.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23412 entries, 0 to 23411\nData columns (total 21 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Date                        23412 non-null  object \n 1   Time                        23412 non-null  object \n 2   Latitude                    23412 non-null  float64\n 3   Longitude                   23412 non-null  float64\n 4   Type                        23412 non-null  object \n 5   Depth                       23412 non-null  float64\n 6   Depth Error                 4461 non-null   float64\n 7   Depth Seismic Stations      7097 non-null   float64\n 8   Magnitude                   23412 non-null  float64\n 9   Magnitude Type              23409 non-null  object \n 10  Magnitude Error             327 non-null    float64\n 11  Magnitude Seismic Stations  2564 non-null   float64\n 12  Azimuthal Gap               7299 non-null   float64\n 13  Horizontal Distance         1604 non-null   float64\n 14  Horizontal Error            1156 non-null   float64\n 15  Root Mean Square            17352 non-null  float64\n 16  ID                          23412 non-null  object \n 17  Source                      23412 non-null  object \n 18  Location Source             23412 non-null  object \n 19  Magnitude Source            23412 non-null  object \n 20  Status                      23412 non-null  object \ndtypes: float64(12), object(9)\nmemory usage: 3.8+ MB\n```\n:::\n:::\n\n\n`info` on the other hand gives us a summary of the dataframe, including the number of non-null values in each column (remember back to [types of data](types-of-data)), the data type of each column, and the memory usage of the dataframe. This is useful to quickly check if there are any missing values. In the above output we can see that there are 23412 entries in the dataframe, and that there are some columns with missing data (`Depth Error` for example).\n\n## The importance of data quality\n\nData quality is a very important aspect of data analysis. If the data is not clean, the results of the analysis will not be reliable. There are many ways in which data can be of poor quality, such as missing, incorrect or inconsistent values. It is important to always check the quality of the data before starting any analysis, and Pandas offers a few methods to help with this.\n\nBefore you make use of a dataset, it is a good idea to perform a few checks to ensure that the data is clean. These can include:\n\n- Checking for missing values\n- Checking for duplicate values\n- Checking for incorrect values\n\nLet us see how to do this with the earthquake dataset for a few simple cases. In practice, checking for correctness of a dataset can be a bit of an art requiring specific domain knowledge, but we will cover some basic cases here.\n\n### Checking for missing values\n\nFrequently columns in a dataset will have missing or incomplete data. Pandas can handle missing data in a few ways, such as dropping the rows with missing data, filling the missing data with a value, or interpolating the missing data. Let us see what this looks like by showing the series for the `Depth Error` column.\n\n::: {#9001fbc9 .cell execution_count=5}\n``` {.python .cell-code}\nearthquakes['Depth Error'].info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.series.Series'>\nRangeIndex: 23412 entries, 0 to 23411\nSeries name: Depth Error\nNon-Null Count  Dtype  \n--------------  -----  \n4461 non-null   float64\ndtypes: float64(1)\nmemory usage: 183.0 KB\n```\n:::\n:::\n\n\nNotice how the range is 0 to 23411, but how the Non-Null Count is only 4461. This means that there are 18951 missing values in this column. We can use the `isnull` method to check for missing values across all columns in the dataframe.\n\n::: {#623059a6 .cell execution_count=6}\n``` {.python .cell-code}\nearthquakes.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nDate                              0\nTime                              0\nLatitude                          0\nLongitude                         0\nType                              0\nDepth                             0\nDepth Error                   18951\nDepth Seismic Stations        16315\nMagnitude                         0\nMagnitude Type                    3\nMagnitude Error               23085\nMagnitude Seismic Stations    20848\nAzimuthal Gap                 16113\nHorizontal Distance           21808\nHorizontal Error              22256\nRoot Mean Square               6060\nID                                0\nSource                            0\nLocation Source                   0\nMagnitude Source                  0\nStatus                            0\ndtype: int64\n```\n:::\n:::\n\n\nQuite a few columns have missing values, such as `Depth Error`, `Depth Seismic Stations`, `Magnitude Error`, and `Magnitude Seismic Stations`.\n\nLet us see what missing values look like in the dataframe.\n\n::: {#7af8910b .cell execution_count=7}\n``` {.python .cell-code}\nearthquakes['Depth Error']\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n0        NaN\n1        NaN\n2        NaN\n3        NaN\n4        NaN\n        ... \n23407    1.2\n23408    2.0\n23409    1.8\n23410    1.8\n23411    2.2\nName: Depth Error, Length: 23412, dtype: float64\n```\n:::\n:::\n\n\nThe entries with missing values are shown as `NaN`, which stands for \"Not a Number\".\n\nPandas offers a few methods to handle missing values, such as `dropna` (will drop any rows with missing values), `fillna` (substitutes a missing value with a prescribed value), and `interpolate` (will fill in missing values with interpolated values).\n\nAs an example, let us drop any rows with a missing `Magnitude Type`.\n\n::: {#f80de44b .cell execution_count=8}\n``` {.python .cell-code}\nearthquakes = earthquakes.dropna(\n    subset=['Magnitude Type'],\n    ignore_index=True\n)\n```\n:::\n\n\nThe `dropna` method has a few arguments that can be used to customize the behavior. In the example above, we used the `subset` argument to specify that we only want to drop rows where the `Magnitude Type` column is missing. We also used the `ignore_index` argument to reset the index of the dataframe after dropping the rows.\n\n:::{.callout-note}\n## About the `ignore_index` argument\n\nDataframes in Pandas always have an index which is used to identify the rows. When you drop rows from a dataframe, the index is not automatically reset. This can be a problem if you want to iterate over the rows of the dataframe, as the index will have gaps. The `ignore_index` argument can be used to reset the index after dropping rows. You will come across many cases where you will need to reset the index of a dataframe, so it is good to be aware of this.\n:::\n\nLet us now look at the dataframe again to see if the rows with missing `Magnitude Type` have been dropped.\n\n::: {#b7b4a8fb .cell execution_count=9}\n``` {.python .cell-code}\nearthquakes.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23409 entries, 0 to 23408\nData columns (total 21 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Date                        23409 non-null  object \n 1   Time                        23409 non-null  object \n 2   Latitude                    23409 non-null  float64\n 3   Longitude                   23409 non-null  float64\n 4   Type                        23409 non-null  object \n 5   Depth                       23409 non-null  float64\n 6   Depth Error                 4461 non-null   float64\n 7   Depth Seismic Stations      7097 non-null   float64\n 8   Magnitude                   23409 non-null  float64\n 9   Magnitude Type              23409 non-null  object \n 10  Magnitude Error             327 non-null    float64\n 11  Magnitude Seismic Stations  2564 non-null   float64\n 12  Azimuthal Gap               7299 non-null   float64\n 13  Horizontal Distance         1604 non-null   float64\n 14  Horizontal Error            1156 non-null   float64\n 15  Root Mean Square            17352 non-null  float64\n 16  ID                          23409 non-null  object \n 17  Source                      23409 non-null  object \n 18  Location Source             23409 non-null  object \n 19  Magnitude Source            23409 non-null  object \n 20  Status                      23409 non-null  object \ndtypes: float64(12), object(9)\nmemory usage: 3.8+ MB\n```\n:::\n:::\n\n\nWe now see 23409 entries in the dataframe, which means that 3 rows were dropped as expected, and RangeIndex correctly shows an index from 0 to 23408.\n\nWe could perform similar operations for other columns with missing values, such as `Depth Error`, `Depth Seismic Stations`, `Magnitude Error`, and `Magnitude Seismic Stations`, but for now we will leave it at that as we are just exemplifying the process.\n\n### Checking for duplicate values\n\nAnother common problem in datasets is duplicate values. These can occur for a variety of reasons, such as data entry errors, or errors in the data collection process. Pandas offers a few methods to check for duplicate values, such as `duplicated` and `drop_duplicates`.\n\nAs an example, let us check for duplicate values in the `ID` column. We do this by using the `duplicated` method, which returns a boolean series indicating whether a value is duplicated or not, and then using the `sum` method to count the number of duplicates.\n\n::: {#01753a17 .cell execution_count=10}\n``` {.python .cell-code}\nearthquakes.duplicated(\n    subset=['ID']\n).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0\n```\n:::\n:::\n\n\nThe result was 0, which means that there are no duplicate values in the `ID` column, good!\n\nLet us now check to try and find duplicate `Latitude` and `Longitude` values, as these could indicate that the same earthquake was recorded more than once by the same, or different stations.\n\n::: {#21488fc8 .cell execution_count=11}\n``` {.python .cell-code}\nearthquakes.duplicated(\n    subset=['Latitude', 'Longitude']\n).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n6\n```\n:::\n:::\n\n\nThere! We found 6 duplicates present. Let us now drop these duplicates with the `drop_duplicates` method.\n\n::: {#5846ce56 .cell execution_count=12}\n``` {.python .cell-code}\nearthquakes = earthquakes.drop_duplicates(subset=['Latitude', 'Longitude'], ignore_index=True)\n```\n:::\n\n\n### Checking for incorrect values\n\nChecking for incorrect values in a dataset can be a bit more challenging, as it requires some domain knowledge. For argument's sake, let us check for large `Horizontal Error` values (in the dataset, `Horizontal Error` is the horizontal error of the location of the earthquake in kilometers, and let us assume that it should not be larger than 90 km).\n\n::: {#3903d8da .cell execution_count=13}\n``` {.python .cell-code}\n(earthquakes['Horizontal Error'] > 90).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n14\n```\n:::\n:::\n\n\nThe above expression `earthquakes['Horizontal Error'] > 90` returns a boolean series indicating whether the condition is met or not, and then we use the `sum` method to count the number of values that meet the condition. In this case, there are 14 earthquakes with a `Horizontal Error` larger than 90 km, which could be incorrect values. Let us now drop these rows.\n\n::: {#da72e364 .cell execution_count=14}\n``` {.python .cell-code}\nearthquakes = earthquakes.drop(\n    earthquakes[earthquakes['Horizontal Error'] > 90].index\n).reset_index(drop=True)\n```\n:::\n\n\nThe above code has a few more details than what we have seen until now. It works by first selecting the rows that meet the condition `earthquakes['Horizontal Error'] > 90`, and then using the `index` attribute to get the index (0, 1, 2, etc.) of the rows that meet the condition. We then use the `drop` method to drop these rows, and finally use the `reset_index` method to reset the index of the dataframe as we have seen before when using the `ignore_index` argument of the `dropna` method.\n\nLet's now check the dataframe to see if the rows with large `Horizontal Error` values have been dropped.\n\n::: {#44dd411a .cell execution_count=15}\n``` {.python .cell-code}\n(earthquakes['Horizontal Error'] > 90).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n0\n```\n:::\n:::\n\n\nPerfect! No more rows with large `Horizontal Error` values!\n\n## Performing simple exploratory data analysis\n\nNow that we have cleaned the data, we can start performing some analysis. By analysis we mean answering questions about the data, such as:\n\n- What is the average magnitude of earthquakes in the dataset?\n- What is the average depth of earthquakes ?\n- How many earthquakes were recorded per year ?\n- What is the average number of stations that recorded an earthquake ?\n\n### Calculating mean values\n\n::: {#063ac495 .cell execution_count=16}\n``` {.python .cell-code}\nearthquakes['Magnitude'].describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\ncount    23389.000000\nmean         5.882655\nstd          0.423149\nmin          5.500000\n25%          5.600000\n50%          5.700000\n75%          6.000000\nmax          9.100000\nName: Magnitude, dtype: float64\n```\n:::\n:::\n\n\nThis code simply uses the `describe` method to show the summary statistics of the `Magnitude` column, which includes the mean value, as well as the standard deviation, minimum, maximum, and quartiles. Alternatively, we could calculate the mean value directly.\n\n::: {#f6dbe524 .cell execution_count=17}\n``` {.python .cell-code}\nearthquakes['Magnitude'].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n5.882655094275087\n```\n:::\n:::\n\n\n### Distribution of data\n\nOne important aspect of data analysis is understanding the distribution of the data. This can be done by plotting histograms or density charts, which show the frequency of values in a dataset. As an example, let us look at the distribution of the `Magnitude` column.\n\n:::{.callout-note}\n## About Data Distribution\n\nUnderstanding the distribution of data is very important in data analysis, as it can help identify patterns and trends. For example, if the data is normally distributed, we can use statistical methods that assume a normal distribution. If the data is not normally distributed, we may need to use non-parametric methods instead.\n\nA great introduction to statistics if you haven't looked very deeply into the topic is Shafer and Zhang's [Introductory Statistics](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)).\n:::\n\n::: {#6f946813 .cell tags='[\"hide-input\"]' execution_count=18}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generate normally distributed integers\nnormal_integers = np.random.normal(loc=0, scale=10, size=1000)\nnormal_integers = np.round(normal_integers).astype(int)\n\n# Generate data for the line (fitted normal distribution)\nx = np.arange(min(normal_integers), max(normal_integers) + 1)\npdf = norm.pdf(x, loc=0, scale=10)  # Normal PDF based on the original distribution\npdf_scaled = pdf * len(normal_integers) * (x[1] - x[0])  # Scale to match histogram\n\n# Plot the histogram\nplt.figure(figsize=(12, 6))\nplt.hist(normal_integers, bins=20, edgecolor='black', alpha=0.7, label='Histogram')\n\n# Overlay the line\nplt.plot(x, pdf_scaled, color='red', label='Normal Distribution Curve')\n\n# Add labels and title\nplt.title('Histogram with Normal Distribution Curve')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){}\n:::\n:::\n\n\nThe usual process to understand a distribution is by dividing the data into ranges (also called \"bins\"), and then counting the number of values in each range. This is what the histogram shows. Let us see how this works.\n\n::: {#c610e455 .cell execution_count=19}\n``` {.python .cell-code}\nearthquakes['Magnitude'].value_counts(bins=4)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n(5.495, 6.4]    21084\n(6.4, 7.3]       2023\n(7.3, 8.2]        269\n(8.2, 9.1]         13\nName: count, dtype: int64\n```\n:::\n:::\n\n\nThis code uses the `value_counts` method to count the number of earthquake magnitudes into four bins (`bins=4`), and returns a series with the counts. Any numerical columns in a dataframe can be divided into bins using this method.\n\nWe can also plot the histogram for the `Magnitude` column using the `plot` method and the `hist` plot kind.\n\n::: {#82863cc5 .cell execution_count=20}\n``` {.python .cell-code}\nearthquakes['Magnitude'].plot(\n    kind='hist',\n    bins=4,\n    title='Earthquakes Magnitude Distribution',\n    figsize=(12, 6)\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-20-output-1.png){}\n:::\n:::\n\n\nThis creates a compelling visualisation of the distribution of magnitudes, and we can see there are a lot of earthquakes with small magnitudes!\n\n### Understanding the relationship between variables\n\nAnother important aspect of data analysis is understanding the relationship between variables. This can be done by computing the correlation between variables, which measures how closely related two variables are. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation, 1 indicates a perfect positive correlation, and 0 indicates no correlation.\n\nPandas offers a `corr` method to compute the correlation between variables. Let us see how this works.\n\n::: {#4abe9836 .cell execution_count=21}\n``` {.python .cell-code}\nearthquakes[\n    ['Magnitude', 'Depth']\n].corr()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Magnitude</th>\n      <th>Depth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Magnitude</th>\n      <td>1.000000</td>\n      <td>0.023299</td>\n    </tr>\n    <tr>\n      <th>Depth</th>\n      <td>0.023299</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhat the resulting matrix shows is the correlation between `Magnitude` and `Depth`, which is 0.023, indicating a very weak positive correlation. This means that as the magnitude of an earthquake increases, the depth of the earthquake also increases, but only very slightly.\n\nWe can run a similar analysis for any number of other columns, for example, let us add `Horizontal Error` to the mix.\n\n::: {#9693d692 .cell execution_count=22}\n``` {.python .cell-code}\nearthquakes[\n    ['Magnitude', 'Depth', 'Horizontal Error']\n].corr()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Magnitude</th>\n      <th>Depth</th>\n      <th>Horizontal Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Magnitude</th>\n      <td>1.000000</td>\n      <td>0.023299</td>\n      <td>-0.128781</td>\n    </tr>\n    <tr>\n      <th>Depth</th>\n      <td>0.023299</td>\n      <td>1.000000</td>\n      <td>0.146771</td>\n    </tr>\n    <tr>\n      <th>Horizontal Error</th>\n      <td>-0.128781</td>\n      <td>0.146771</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow we see a stronger correlation between `Depth` and `Horizontal Error`, which is 0.14. This means that as the depth of an earthquake increases, the horizontal error also increases, but again not by a large factor.\n\nWhen performing this type of analysis between multiple columns, it is interesting to visualy represent the data. One way to do this is by using a scatter plot, which shows the relationship between two variables. Let us see how this works.\n\n:::{.callout-note}\n## About Scatter Plots\n\nScatter plots are a very useful tool to visualize the relationship between two variables. They can help identify patterns and trends in the data, and can be used to identify outliers or anomalies. There are many other types of plots that can be used to visualize data, such as line plots, bar plots, and box plots, which we will use as we progress.\n:::\n\n::: {#3d6e5db3 .cell execution_count=23}\n``` {.python .cell-code}\nearthquakes.plot(\n    kind='scatter',\n    x='Depth',\n    y='Horizontal Error',\n    title='Earthquake Depth vs. Horizontal Error',\n    cmap='viridis',\n    c='Magnitude',\n    figsize=(12, 6)\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){}\n:::\n:::\n\n\nThis plot is showing a visual representation of the correlation between `Depth` and `Horizontal Error`, and colored by `Magnitude`. We can see that there is no clear relationship between the two variables, which is consistent with the correlation coefficient we calculated earlier. The `c` argument is used to color the points by the `Magnitude` column, and the `cmap` argument is used to specify the color map to use. Let us do a similar plot for `Depth` and `Magnitude`.\n\n### Categorical data and grouping\n\nYou will have noticed that some of the columns in the dataset are strings of text, such as `Type` and `Source`. These are called *categorical* data and can be used to group the data and perform analysis. Pandas offers a few methods to work with categorical data, such as `groupby` and `pivot_table`.\n\nAs an example, let us group the data by the `Type` column and calculate the average magnitude of each type of earthquake.\n\n::: {#cf215cae .cell execution_count=24}\n``` {.python .cell-code}\nearthquakes.groupby(\n    'Type'\n)['Magnitude'].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\nType\nEarthquake           5.882775\nExplosion            5.850000\nNuclear Explosion    5.864417\nRock Burst           6.200000\nName: Magnitude, dtype: float64\n```\n:::\n:::\n\n\nWhat this series shows us is the average magnitude of each type of earthquake. For example, the average magnitude of `Earthquake` is aproximately 5.88, and the average magnitude of `Nuclear Explosion` is 5.86.\n\nWe can also use the `pivot_table` method to group the data by multiple columns. A pivot table is a way to summarize data in a table format, and can be used to perform more complex analysis. Let us see how this works, this time by grouping the data by `Type` and `Source`.\n\n::: {#c7b4b183 .cell execution_count=25}\n``` {.python .cell-code}\n# Pivot Type and Magnitude\nearthquakes.pivot_table(\n    values='Magnitude',\n    index=['Type', 'Source'],\n    aggfunc='mean'\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Magnitude</th>\n    </tr>\n    <tr>\n      <th>Type</th>\n      <th>Source</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"12\" valign=\"top\">Earthquake</th>\n      <th>AK</th>\n      <td>5.858333</td>\n    </tr>\n    <tr>\n      <th>CI</th>\n      <td>6.037778</td>\n    </tr>\n    <tr>\n      <th>GCMT</th>\n      <td>5.885455</td>\n    </tr>\n    <tr>\n      <th>ISCGEM</th>\n      <td>6.007805</td>\n    </tr>\n    <tr>\n      <th>ISCGEMSUP</th>\n      <td>6.000833</td>\n    </tr>\n    <tr>\n      <th>NC</th>\n      <td>6.029804</td>\n    </tr>\n    <tr>\n      <th>NN</th>\n      <td>5.725000</td>\n    </tr>\n    <tr>\n      <th>OFFICIAL</th>\n      <td>8.712500</td>\n    </tr>\n    <tr>\n      <th>PR</th>\n      <td>5.800000</td>\n    </tr>\n    <tr>\n      <th>SE</th>\n      <td>5.800000</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>5.865256</td>\n    </tr>\n    <tr>\n      <th>UW</th>\n      <td>5.966667</td>\n    </tr>\n    <tr>\n      <th>Explosion</th>\n      <th>US</th>\n      <td>5.850000</td>\n    </tr>\n    <tr>\n      <th>Nuclear Explosion</th>\n      <th>US</th>\n      <td>5.864417</td>\n    </tr>\n    <tr>\n      <th>Rock Burst</th>\n      <th>US</th>\n      <td>6.200000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhat this table shows us is the average magnitude of each type of earthquake, grouped by the source of the data, which is a more complex analysis than what we did before. A pivot table can be used to group data by multiple columns, and to perform more complex calculations, such as calculating the sum, mean, or median of a column. In the example above we used the `aggfunc` argument to specify that we want to calculate the mean of the `Magnitude` column. We could have used `aggfunc='median'` to calculate the median of the `Magnitude` column instead (`aggfunc` stands for \"aggregation function\").\n\n### Using dates in our analysis\n\nLet's now calculate the average magnitude of the earthquakes that occurred in a given year. If you look back at the data, you will see that the `Date` column contains the date and time of each earthquake. We can use this column to select a given year, and then calculate the average magnitude of the earthquakes that occurred in that year.\n\nNotice however the `Date` format is an `object` type, which means that it is a string. We need to convert it to a `datetime` object to be able to extract the year. We can do this with the `to_datetime` method.\n\n:::{.callout-note}\n## About `datetime` Objects\n\n`datetime` objects are a very useful data type in Python, and Pandas offers a lot of functionality to work with them. You will come across them frequently when working with time series data, and it is good to be familiar with them.\n:::\n\n::: {#49317508 .cell execution_count=26}\n``` {.python .cell-code}\nearthquakes['Date'] = pd.to_datetime(\n    earthquakes['Date'],\n    format='%m/%d/%Y',\n    errors='coerce'\n)\n```\n:::\n\n\nThe above looks a bit special, but it is actually quite simple. We are using the `to_datetime` method of the Pandas library to convert dates formated as 'month/day/year' (commonly used in the United States, unlike 'day/month/year' used in Europe) to a `datetime` object, with `errors='coerce'` instructing the method to return `NaT` (Not a Time) for any dates that cannot be converted.\n\nNow let us extract the year from the `Date` column, and add it as a new column to the dataframe.\n\n::: {#a123c124 .cell execution_count=27}\n``` {.python .cell-code}\nearthquakes['Year'] = earthquakes['Date'].dt.year\n```\n:::\n\n\nThe above code uses the `dt` accessor to access the `year` attribute of the `Date` column, and then assigns it to a new column named `Year`.\n\n:::{.callout-note}\n## About Accessors\n\nAn accessor is a way to access the elements of a data structure. In this case, the `dt` accessor is used to access the elements of a `datetime` object, such as the year, month, day, etc. Accessors are useful when working with data structures that contain complex data types, such as `datetime` objects.\n:::\n\nWe can now check the dataframe to see if the `Year` column was added.\n\n::: {#47f10d6c .cell execution_count=28}\n``` {.python .cell-code}\nearthquakes['Year']\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n0        1965.0\n1        1965.0\n2        1965.0\n3        1965.0\n4        1965.0\n          ...  \n23384    2016.0\n23385    2016.0\n23386    2016.0\n23387    2016.0\n23388    2016.0\nName: Year, Length: 23389, dtype: float64\n```\n:::\n:::\n\n\nWorked! Did you notice however that the `Year` column is a `float` ? This is because the `dt.year` accessor returns a `float` type. We can convert it to an `int` type just to make it look nicer, but also because it makes more sense to have years as integers. We do this with the `astype` method.\n\n::: {#e629a486 .cell execution_count=29}\n``` {.python .cell-code}\n# Fill NaN values before converting\nearthquakes['Year'] = earthquakes['Year'].fillna(0).astype(int)\n\nearthquakes['Year']\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n0        1965\n1        1965\n2        1965\n3        1965\n4        1965\n         ... \n23384    2016\n23385    2016\n23386    2016\n23387    2016\n23388    2016\nName: Year, Length: 23389, dtype: int64\n```\n:::\n:::\n\n\nNow that we have a `Year` column, we can calculate the average magnitude of the earthquakes that occurred in a given year.\n\n::: {#a2260482 .cell execution_count=30}\n``` {.python .cell-code}\nearthquakes[earthquakes['Year'] == 1972]['Magnitude'].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\n5.943814432989692\n```\n:::\n:::\n\n\nGreat! We can even plot some of this data in interesting ways using the `matplotlib` library. Let us see how to do this.\n\n::: {#98e9cab1 .cell execution_count=31}\n``` {.python .cell-code}\nearthquakes[earthquakes['Year'] == 1972].plot(\n    kind='scatter',\n    x='Date',\n    y='Magnitude',\n    title='Earthquakes in 1972',\n    colormap='rainbow',\n    c='Depth',\n    figsize=(12, 6)\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-31-output-1.png){}\n:::\n:::\n\n\nHere we are plotting the Date vs the Magnitude of the earthquakes. The `plot` method is used to create the plot, and the `scatter` plot kind is used to create a scatter plot. The `c` argument is used to color the points by the `Depth` column, and the `cmap` argument is used to specify the color map to use. The `x` and `y` attributes are used to set the columns for the x and y axes, and the `title` method is used to set the title of the plot.\n\nWe can also use the `plot` method to create a line plot, which shows the relationship between two variables over time. We could for example plot the average magnitude of earthquakes over time by aggregating the data by a given time period.\n\n::: {#fe0bc9e4 .cell execution_count=32}\n``` {.python .cell-code}\navg_magnitude_per_year = earthquakes.resample(\n    rule='YE',\n    on='Date'\n)['Magnitude'].mean()\n\navg_magnitude_per_year.plot(\n    kind='line',\n    title='Average Earthquake Magnitude per Year',\n    ylabel='Average Magnitude',\n    figsize=(12, 6)\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-32-output-1.png){}\n:::\n:::\n\n\nIn the above code, we are taking a few steps:\n\n- We are resampling the data by year using the `resample` method (`rule='YE'` means that we are resampling by year).\n- We are calculating the mean of the `Magnitude` column for each year using the `mean` method.\n- We then use the `plot` method to create a line plot of the data.\n\nTo make this clearer, let us show the calculated `avg_magnitude_per_year` series for the first five years.\n\n::: {#2b3df140 .cell execution_count=33}\n``` {.python .cell-code}\navg_magnitude_per_year.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nDate\n1965-12-31    6.014159\n1966-12-31    6.040948\n1967-12-31    6.003922\n1968-12-31    6.081848\n1969-12-31    6.009938\nName: Magnitude, dtype: float64\n```\n:::\n:::\n\n\n### Using geographical data effectively\n\nYou will have noticed (hopefully) that the dataset contains geographical data in the form of `Latitude` and `Longitude`. This data can be used to create maps and to perform spatial analysis. For example, we could create a map of the earthquakes in the dataset, or we could filter out the earthquakes that occurred in a given region of the planet.\n\nLet us take a simple example, and filter out the earthquakes that occurred around the region of the Azores islands. We will consider the region to be between 36 and 42 degrees latitude, and between -31 and -24 degrees longitude.\n\n::: {#c3191d42 .cell execution_count=34}\n``` {.python .cell-code}\nazores_earthquakes = earthquakes[\n    earthquakes['Latitude'].between(36, 42) &\n    earthquakes['Longitude'].between(-31, -24)\n]\n\nazores_earthquakes\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5381</th>\n      <td>1980-01-01</td>\n      <td>16:42:40</td>\n      <td>38.815</td>\n      <td>-27.780</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.7</td>\n      <td>MS</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP00014TU</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n      <td>1980</td>\n    </tr>\n    <tr>\n      <th>9065</th>\n      <td>1988-07-22</td>\n      <td>21:16:04</td>\n      <td>39.862</td>\n      <td>-29.589</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.5</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>USP0003J40</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>1988</td>\n    </tr>\n    <tr>\n      <th>9230</th>\n      <td>1988-11-21</td>\n      <td>16:55:53</td>\n      <td>37.938</td>\n      <td>-26.142</td>\n      <td>Earthquake</td>\n      <td>10.8</td>\n      <td>2.9</td>\n      <td>NaN</td>\n      <td>5.9</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.90</td>\n      <td>USP0003P1Z</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>1988</td>\n    </tr>\n    <tr>\n      <th>9301</th>\n      <td>1989-01-21</td>\n      <td>02:52:20</td>\n      <td>38.147</td>\n      <td>-26.243</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.7</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.80</td>\n      <td>USP0003R1R</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>1989</td>\n    </tr>\n    <tr>\n      <th>9512</th>\n      <td>1989-06-26</td>\n      <td>10:38:39</td>\n      <td>39.112</td>\n      <td>-28.242</td>\n      <td>Earthquake</td>\n      <td>11.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.9</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.10</td>\n      <td>USP0003WP5</td>\n      <td>US</td>\n      <td>US</td>\n      <td>NC</td>\n      <td>Reviewed</td>\n      <td>1989</td>\n    </tr>\n    <tr>\n      <th>12920</th>\n      <td>1996-03-09</td>\n      <td>22:35:38</td>\n      <td>37.034</td>\n      <td>-24.374</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.7</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.20</td>\n      <td>USP0007EJ0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>13564</th>\n      <td>1997-06-27</td>\n      <td>04:39:53</td>\n      <td>38.334</td>\n      <td>-26.684</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.9</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.09</td>\n      <td>USP0008416</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>1997</td>\n    </tr>\n    <tr>\n      <th>14010</th>\n      <td>1998-07-09</td>\n      <td>05:19:07</td>\n      <td>38.650</td>\n      <td>-28.626</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.2</td>\n      <td>MWB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.98</td>\n      <td>USP0008R70</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n      <td>1998</td>\n    </tr>\n    <tr>\n      <th>16548</th>\n      <td>2003-12-23</td>\n      <td>14:02:04</td>\n      <td>40.135</td>\n      <td>-29.692</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>282.0</td>\n      <td>5.6</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>60.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.91</td>\n      <td>USP000CFW0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>18364</th>\n      <td>2007-04-05</td>\n      <td>03:56:50</td>\n      <td>37.306</td>\n      <td>-24.621</td>\n      <td>Earthquake</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>627.0</td>\n      <td>6.3</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>23.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.82</td>\n      <td>USP000F8R5</td>\n      <td>US</td>\n      <td>US</td>\n      <td>GCMT</td>\n      <td>Reviewed</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>18369</th>\n      <td>2007-04-07</td>\n      <td>07:09:25</td>\n      <td>37.306</td>\n      <td>-24.494</td>\n      <td>Earthquake</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>645.0</td>\n      <td>6.1</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>19.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.95</td>\n      <td>USP000F8YJ</td>\n      <td>US</td>\n      <td>US</td>\n      <td>GCMT</td>\n      <td>Reviewed</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>21706</th>\n      <td>2013-04-30</td>\n      <td>06:25:23</td>\n      <td>37.592</td>\n      <td>-24.913</td>\n      <td>Earthquake</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>599.0</td>\n      <td>5.9</td>\n      <td>MWW</td>\n      <td>...</td>\n      <td>27.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.77</td>\n      <td>US2013PQAF</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n      <td>2013</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows Ã— 22 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe above code should be self explanatory - we are filtering the dataframe by selecting the rows where the `Latitude` is between 36 and 42 degrees, and (the symbol `&` means \"and\") the `Longitude` is between -31 and -24 degrees. Now that we have the list, let us calculate the minimum, maximum, and average magnitude of the earthquakes that occurred in this region.\n\n::: {#2db83515 .cell execution_count=35}\n``` {.python .cell-code}\nazores_min_magnitude = azores_earthquakes['Magnitude'].min()\nazores_max_magnitude = azores_earthquakes['Magnitude'].max()\nazores_mean_magnitude = azores_earthquakes['Magnitude'].mean()\n\nazores_min_magnitude, azores_max_magnitude, azores_mean_magnitude\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n(5.5, 6.7, 5.95)\n```\n:::\n:::\n\n\n:::{.callout-note}\n## About Box Plots\n\nThere's a neat type of plot called a `boxplot` that can be used to visualize the distribution of data. It shows the median, quartiles, and outliers of the data. We don't need to go into the details of how it works for now, but it is useful to know that it exists and that it can be used to visualize the distribution of a given column.\n:::\n\n::: {#eccef2da .cell tags='[\"hide-input\"]' execution_count=36}\n``` {.python .cell-code}\nazores_earthquakes['Magnitude'].plot(\n    kind='box',\n    title='Azores Earthquakes Magnitude Distribution',\n    figsize=(12, 6),\n    vert=False\n)\n\nplt.text(azores_min_magnitude, 1, f'Min: {azores_min_magnitude:.2f}', va='center', ha='left', color='blue')\nplt.text(azores_max_magnitude, 1, f'Max: {azores_max_magnitude:.2f}', va='center', ha='right', color='red')\nplt.text(azores_mean_magnitude, 1.1, f'Mean: {azores_mean_magnitude:.2f}', va='center', ha='center', color='green')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-36-output-1.png){}\n:::\n:::\n\n\nBecause we have a small dataset, we can also plot the earthquakes on a map. For this we will use the `folium` library which we can install with the `conda` command (by now you should be able to do this without further instruction).\n\n::: {#18cf559c .cell execution_count=37}\n``` {.python .cell-code}\nimport folium\n\n# Create a map centered around the Azores\nazores_map = folium.Map(\n    location=[38, -28],\n    zoom_start=6.5\n)\n\n# Add markers for each earthquake\nfor _, row in azores_earthquakes.iterrows():\n    folium.CircleMarker(\n        location=[row['Latitude'], row['Longitude']],\n        radius=row['Magnitude'],  # Scale the circle size by magnitude\n        color='blue',\n        fill=True,\n        fill_opacity=0.3,\n        popup=f\"Year: {int(row['Year'])} Magnitude: {row['Magnitude']}, Depth: {row['Depth']} km\"\n    ).add_to(azores_map)\n\n# Display the map\nazores_map\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    \n    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n    \n        &lt;script&gt;\n            L_NO_TOUCH = false;\n            L_DISABLE_3D = false;\n        &lt;/script&gt;\n    \n    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n    \n            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n            &lt;style&gt;\n                #map_98707f855dbe2467d30cb6f3b4af02aa {\n                    position: relative;\n                    width: 100.0%;\n                    height: 100.0%;\n                    left: 0.0%;\n                    top: 0.0%;\n                }\n                .leaflet-container { font-size: 1rem; }\n            &lt;/style&gt;\n        \n&lt;/head&gt;\n&lt;body&gt;\n    \n    \n            &lt;div class=&quot;folium-map&quot; id=&quot;map_98707f855dbe2467d30cb6f3b4af02aa&quot; &gt;&lt;/div&gt;\n        \n&lt;/body&gt;\n&lt;script&gt;\n    \n    \n            var map_98707f855dbe2467d30cb6f3b4af02aa = L.map(\n                &quot;map_98707f855dbe2467d30cb6f3b4af02aa&quot;,\n                {\n                    center: [38.0, -28.0],\n                    crs: L.CRS.EPSG3857,\n                    ...{\n  &quot;zoom&quot;: 6.5,\n  &quot;zoomControl&quot;: true,\n  &quot;preferCanvas&quot;: false,\n}\n\n                }\n            );\n\n            \n\n        \n    \n            var tile_layer_fb10417f5122c5e98c73c129c76eb2d9 = L.tileLayer(\n                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n                {\n  &quot;minZoom&quot;: 0,\n  &quot;maxZoom&quot;: 19,\n  &quot;maxNativeZoom&quot;: 19,\n  &quot;noWrap&quot;: false,\n  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n  &quot;subdomains&quot;: &quot;abc&quot;,\n  &quot;detectRetina&quot;: false,\n  &quot;tms&quot;: false,\n  &quot;opacity&quot;: 1,\n}\n\n            );\n        \n    \n            tile_layer_fb10417f5122c5e98c73c129c76eb2d9.addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n            var circle_marker_4ec0ad77553465ccb9dc04f44517ba36 = L.circleMarker(\n                [38.815, -27.78],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6.7, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_ff47e661c308d4c37b0d801f248b187d = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_a2c6fed17ea2aee9cce053d8dc59c1dc = $(`&lt;div id=&quot;html_a2c6fed17ea2aee9cce053d8dc59c1dc&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1980 Magnitude: 6.7, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_ff47e661c308d4c37b0d801f248b187d.setContent(html_a2c6fed17ea2aee9cce053d8dc59c1dc);\n            \n        \n\n        circle_marker_4ec0ad77553465ccb9dc04f44517ba36.bindPopup(popup_ff47e661c308d4c37b0d801f248b187d)\n        ;\n\n        \n    \n    \n            var circle_marker_ba993ed786ca348b586c8164f605f448 = L.circleMarker(\n                [39.862, -29.589],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.5, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_d0fd1be614ad994ec5c306e92d47cf60 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_5b4113395c8f9fce63d57a54af49096f = $(`&lt;div id=&quot;html_5b4113395c8f9fce63d57a54af49096f&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1988 Magnitude: 5.5, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_d0fd1be614ad994ec5c306e92d47cf60.setContent(html_5b4113395c8f9fce63d57a54af49096f);\n            \n        \n\n        circle_marker_ba993ed786ca348b586c8164f605f448.bindPopup(popup_d0fd1be614ad994ec5c306e92d47cf60)\n        ;\n\n        \n    \n    \n            var circle_marker_955f68c973669c6dc1f330c394252ebf = L.circleMarker(\n                [37.938, -26.142],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.9, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_89aeca972225d8d9b859290ab6cf1411 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_e473b44d288e5025451d90f97a486ae6 = $(`&lt;div id=&quot;html_e473b44d288e5025451d90f97a486ae6&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1988 Magnitude: 5.9, Depth: 10.8 km&lt;/div&gt;`)[0];\n                popup_89aeca972225d8d9b859290ab6cf1411.setContent(html_e473b44d288e5025451d90f97a486ae6);\n            \n        \n\n        circle_marker_955f68c973669c6dc1f330c394252ebf.bindPopup(popup_89aeca972225d8d9b859290ab6cf1411)\n        ;\n\n        \n    \n    \n            var circle_marker_36e807f6e86a9f316ddb84c4f01d2657 = L.circleMarker(\n                [38.147, -26.243],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.7, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_3ec38b8fe935ffd3ac87f5c3124edcc5 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_9dc7beb1cfc9a4b835ede2150bc167ad = $(`&lt;div id=&quot;html_9dc7beb1cfc9a4b835ede2150bc167ad&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1989 Magnitude: 5.7, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_3ec38b8fe935ffd3ac87f5c3124edcc5.setContent(html_9dc7beb1cfc9a4b835ede2150bc167ad);\n            \n        \n\n        circle_marker_36e807f6e86a9f316ddb84c4f01d2657.bindPopup(popup_3ec38b8fe935ffd3ac87f5c3124edcc5)\n        ;\n\n        \n    \n    \n            var circle_marker_8902c61d05ba90790b166fb0b89a7bfb = L.circleMarker(\n                [39.112, -28.242],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.9, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_51f464bfc4d663d50cc8a66ff99b5472 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_205d2e4f42b9ea050f61ba8c55930f05 = $(`&lt;div id=&quot;html_205d2e4f42b9ea050f61ba8c55930f05&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1989 Magnitude: 5.9, Depth: 11.3 km&lt;/div&gt;`)[0];\n                popup_51f464bfc4d663d50cc8a66ff99b5472.setContent(html_205d2e4f42b9ea050f61ba8c55930f05);\n            \n        \n\n        circle_marker_8902c61d05ba90790b166fb0b89a7bfb.bindPopup(popup_51f464bfc4d663d50cc8a66ff99b5472)\n        ;\n\n        \n    \n    \n            var circle_marker_e331c9da049840ea3f228ef116672e06 = L.circleMarker(\n                [37.034, -24.374],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.7, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_5bed760098b617c9d6733bc4024ec080 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_c6c9697a9fff25de07af1174a438eae1 = $(`&lt;div id=&quot;html_c6c9697a9fff25de07af1174a438eae1&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1996 Magnitude: 5.7, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_5bed760098b617c9d6733bc4024ec080.setContent(html_c6c9697a9fff25de07af1174a438eae1);\n            \n        \n\n        circle_marker_e331c9da049840ea3f228ef116672e06.bindPopup(popup_5bed760098b617c9d6733bc4024ec080)\n        ;\n\n        \n    \n    \n            var circle_marker_5c608882106a2034e5053a4a7a606ed1 = L.circleMarker(\n                [38.334, -26.684],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.9, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_aabfaaf72ab9172d919109405c67a431 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_fda30bd690baa0f345464f4f7aaa5301 = $(`&lt;div id=&quot;html_fda30bd690baa0f345464f4f7aaa5301&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1997 Magnitude: 5.9, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_aabfaaf72ab9172d919109405c67a431.setContent(html_fda30bd690baa0f345464f4f7aaa5301);\n            \n        \n\n        circle_marker_5c608882106a2034e5053a4a7a606ed1.bindPopup(popup_aabfaaf72ab9172d919109405c67a431)\n        ;\n\n        \n    \n    \n            var circle_marker_08bb9b19ade640351932e4582856b6e0 = L.circleMarker(\n                [38.65, -28.626],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6.2, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_d4882c8e2d8053eeb5cc747185d70e88 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_dac4923f3c90c03d89b4fb44b43cc3bd = $(`&lt;div id=&quot;html_dac4923f3c90c03d89b4fb44b43cc3bd&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 1998 Magnitude: 6.2, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_d4882c8e2d8053eeb5cc747185d70e88.setContent(html_dac4923f3c90c03d89b4fb44b43cc3bd);\n            \n        \n\n        circle_marker_08bb9b19ade640351932e4582856b6e0.bindPopup(popup_d4882c8e2d8053eeb5cc747185d70e88)\n        ;\n\n        \n    \n    \n            var circle_marker_66c2d622f747f30ca253d2f58ecf4321 = L.circleMarker(\n                [40.135, -29.692],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.6, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_b200fee2865f9c5b27ee9f384bda101d = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_ce2f92b3d2b1ffe58b0d9ee5adc96196 = $(`&lt;div id=&quot;html_ce2f92b3d2b1ffe58b0d9ee5adc96196&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 2003 Magnitude: 5.6, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_b200fee2865f9c5b27ee9f384bda101d.setContent(html_ce2f92b3d2b1ffe58b0d9ee5adc96196);\n            \n        \n\n        circle_marker_66c2d622f747f30ca253d2f58ecf4321.bindPopup(popup_b200fee2865f9c5b27ee9f384bda101d)\n        ;\n\n        \n    \n    \n            var circle_marker_8cbc0bc44c62837259776297bf698858 = L.circleMarker(\n                [37.306, -24.621],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6.3, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_151e5cbe5d6aef6e47b7bcf50f15e0d9 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_da4ef63004c028852e1157a5c1db246d = $(`&lt;div id=&quot;html_da4ef63004c028852e1157a5c1db246d&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 2007 Magnitude: 6.3, Depth: 14.0 km&lt;/div&gt;`)[0];\n                popup_151e5cbe5d6aef6e47b7bcf50f15e0d9.setContent(html_da4ef63004c028852e1157a5c1db246d);\n            \n        \n\n        circle_marker_8cbc0bc44c62837259776297bf698858.bindPopup(popup_151e5cbe5d6aef6e47b7bcf50f15e0d9)\n        ;\n\n        \n    \n    \n            var circle_marker_6898bbf01ae7f1c07eadcec662189516 = L.circleMarker(\n                [37.306, -24.494],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 6.1, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_0efcbbeab0ea93c4d35b97dcd6d0cc5f = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_810e22e47568de7fbea091ef09e646fd = $(`&lt;div id=&quot;html_810e22e47568de7fbea091ef09e646fd&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 2007 Magnitude: 6.1, Depth: 8.0 km&lt;/div&gt;`)[0];\n                popup_0efcbbeab0ea93c4d35b97dcd6d0cc5f.setContent(html_810e22e47568de7fbea091ef09e646fd);\n            \n        \n\n        circle_marker_6898bbf01ae7f1c07eadcec662189516.bindPopup(popup_0efcbbeab0ea93c4d35b97dcd6d0cc5f)\n        ;\n\n        \n    \n    \n            var circle_marker_76e970bef0b8e7a8838bce09404c6177 = L.circleMarker(\n                [37.592, -24.913],\n                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.3, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5.9, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n            ).addTo(map_98707f855dbe2467d30cb6f3b4af02aa);\n        \n    \n        var popup_61b17fc728abdd56daaf161108d6ca07 = L.popup({\n  &quot;maxWidth&quot;: &quot;100%&quot;,\n});\n\n        \n            \n                var html_aff55c2371ca746db6aa7e37b72f7627 = $(`&lt;div id=&quot;html_aff55c2371ca746db6aa7e37b72f7627&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Year: 2013 Magnitude: 5.9, Depth: 10.0 km&lt;/div&gt;`)[0];\n                popup_61b17fc728abdd56daaf161108d6ca07.setContent(html_aff55c2371ca746db6aa7e37b72f7627);\n            \n        \n\n        circle_marker_76e970bef0b8e7a8838bce09404c6177.bindPopup(popup_61b17fc728abdd56daaf161108d6ca07)\n        ;\n\n        \n    \n&lt;/script&gt;\n&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>\n```\n:::\n:::\n\n\nThe code above produces an interactive map which you can zoom in and out of, and click on the markers to see the details of each earthquake. To do so we follow a few steps:\n\n- We create a `Map` object using the `folium` library, and set the center of the map roughly to the Azores islands.\n- We iterate over the rows of the `azores_earthquakes` dataframe with a `for` loop, and add a marker for each earthquake to the map.\n- We then display the map.\n\n## Exercises\n\n1. Calculate the average depth of the earthquakes that occurred in a given year.\n2. Calculate the average number of stations that recorded an earthquake (you can uniquely identify an earthquake with the `ID` column) in a given year.\n3. Calculate the average magnitude of the earthquakes that occurred in a given year, grouped by the `Type` column.\n4. Explain the above code that creates a map of the earthquakes in the dataset. What does each line do?\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}