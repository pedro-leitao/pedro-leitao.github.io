{
  "hash": "e69c473a97413160a1093c7c72113fc4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'How GPU''s work, an explainer using the Mandelbrot set'\nsubtitle: mandelbrot sets and parallelism\ndate: 2025-02-09\ntags: \n    - Experiments\n    - GPU\ncategories:\n    - Experiments\n    - GPU\njupyter: python3\n---\n\n\n\nEvery day pretty much all of us either uses or hears about the mythical GPU, the Graphics Processing Unit. It's the thing that makes your games, video renders, and your machine learning models train faster. But how does it achieve that? What makes it different from a CPU?\n\nWe will do a quick explainer which should give you a good intuition using the [Mandelbrot set](https://www.quantamagazine.org/the-quest-to-decode-the-mandelbrot-set-maths-famed-fractal-20240126/). The Mandelbrot set is a fractal, a set of complex numbers that when iterated through a function, either diverges to infinity or stays bounded, it is the boundary between these two regions. The Mandelbrot set is a great example to use because it's a simple function that can be parallelized easily.\n\n\n## A quick diversion into parallelism\n\nDuring my university days I had a quick course on parallelism, where we were asked how we could parallelize the computation of the Mandelbrot set. The answer is simple, we can calculate each pixel independently, since at its core, calculating the set involves applying a function to each complex number to determine if it belongs to the set or not.\n\nBack then the approach I followed was to divide the image into an $n x n$ grid and assign each grid to a separate networked computer, which would then calculate the pixels in that grid, and write results to a network shared file (this was back in the day where RPC was barely a thing). This is a simple form of parallelism, and it's called [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel).\n\nMost GPU computations are embarrassingly parallel, and this is why they are so good at simple parallelism workloads. They have thousands of cores, and each core can act independently to compute a fragment of the workload.\n\nThey are adept at machine learning and AI workloads equally because most of the computations in these fields are matrix multiplications, which can be parallelized easily.\n\n## The Mandelbrot set\n\nThe Mandelbrot set is defined by the following function:\n\n$$\nf(z) = z^2 + c\n$$\n\nwhere $z$ is a complex number, and $c$ is a constant complex number. We can iterate this function, and if the magnitude of $z$ is greater than 2, then we can say that the function diverges to infinity. If it doesn't, then it stays bounded. The Mandelbrot set is the boundary between these two regions.\n\nFurther below we will show a rendered image of the Mandelbrot set, but first, let's write a simple Python function to calculate it.\n\n## Calculating the Mandelbrot set with no parallelism\n\nLet's start by writing a simple, naive function to calculate the Mandelbrot set. This function uses *no* parallelism, and it's a simple for loop that iterates over each pixel in the image and calculates each using the CPU only. It basically iterates over columns and rows and computes whether that particular point diverges or not as nested loops.\n\nFor a width of 500 and height of 500, this function will compute $250000$ pixels, for a width of 1000 and height of 1000, it will compute $1000000$ pixels, and so on. The time taken for this function to run increase as $O(n^2)$ where $n$ is the width or height of the image.\n\n::: {#68e56eb5 .cell execution_count=2}\n``` {.python .cell-code}\ndef compute_mandelbrot_iterations(width, height, max_iter):\n    real_min, real_max = -2, 1\n    imag_min, imag_max = -1.5, 1.5\n    real_step = (real_max - real_min) / (width - 1)\n    imag_step = (imag_max - imag_min) / (height - 1)\n    \n    # Initialize a 2D list to hold iteration counts.\n    iter_counts = [[0 for _ in range(width)] for _ in range(height)]\n    \n    for j in range(height):\n        imag = imag_min + j * imag_step\n        for i in range(width):\n            real = real_min + i * real_step\n            c = complex(real, imag)\n            z = 0j\n            count = 0\n            while count < max_iter:\n                z = z * z + c\n                # Check divergence: if |z|^2 > 4 then break.\n                if (z.real * z.real + z.imag * z.imag) > 4:\n                    break\n                count += 1\n            iter_counts[j][i] = count\n    \n    return iter_counts\n```\n:::\n\n\n## Calculating the Mandelbrot set with parallelism\n\nWhile the above function is simple, it is not the most efficient. Because it is basically a big matrix operation (an image *is* a matrix), we can parallelize it easily using a number of frameworks which offer matrix operations. Let's investigate how we would do this using a number of libraries.\n\nFor this example, we will show how to achieve it using `numpy`, `pytorch` and Apple's `mlx`. They all offer a similar API, and can be used virtually interchangeably. They offer a set of functionality which allows you to perform matrix operations on either the CPU and GPU:\n\n- Vectorized Operations: They all let you perform elementwise operations on entire arrays/tensors without explicit loops, which boosts performance.\n- Broadcasting: NumPy, PyTorch, and MLX support broadcasting, allowing operations on arrays of different shapes — great for aligning matrices without manual reshaping.\n- Optimized Backends: Under the hood, they rely on highly optimized C/C++ libraries (like BLAS/LAPACK or Apple’s Accelerate framework for MLX) to perform computations quickly.\n- Multi-dimensional Data Handling: They all offer robust support for multi-dimensional arrays (or tensors), making them well-suited for tasks ranging from basic linear algebra to complex machine learning computations.\n\n### Numpy\n\nLet's start with an implementation of the `compute_mandelbrot_iterations` function using `numpy`, entirely with array (or matrix) operations.\n\n::: {#4f011e40 .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\n\ndef compute_mandelbrot_numpy(width:int = 500, height:int = 500, max_iter:int = 30) -> np.ndarray:\n    # Create linearly spaced real and imaginary parts and generate a complex grid.\n    real = np.linspace(-2, 1, width)\n    imag = np.linspace(-1.5, 1.5, height)\n    X, Y = np.meshgrid(real, imag, indexing='xy')\n    c = X + 1j * Y\n\n    # Initialize z and an array to hold the iteration counts\n    z = np.zeros_like(c)\n    iter_counts = np.zeros(c.shape, dtype=np.int32)\n\n    for _ in range(max_iter):\n        # Create a mask for points that have not yet diverged\n        mask = np.abs(z) < 4\n        if not mask.any():\n            break\n        \n        # Update z and iteration counts only where |z| < 4\n        z = np.where(mask, z * z + c, z)\n        iter_counts = np.where(mask, iter_counts + 1, iter_counts)\n\n    return iter_counts\n```\n:::\n\n\nThis function starts by generating a grid of complex numbers using matrix operations, which is key for parallel computation. It first creates two linearly spaced arrays for the real and imaginary parts using `np.linspace`, and then builds two 2D grids with `np.meshgrid` — one for the real values and one for the imaginary values. These grids are combined into a single complex grid `c` (where each element is of the form `x + 1j * y`), and this process happens all at once without the need for explicit loops, leveraging NumPy’s vectorized operations.\n\nNext, the code initializes two arrays of the same shape as `c`: one for the iterative values `z` (starting at zero) and one to keep track of the iteration counts. The main computation occurs in a loop where, in each iteration, the code computes the absolute value of every element in `z` simultaneously using `np.abs(z)` and creates a boolean mask that identifies the elements where `|z| < 4`. This mask is then used to update `z` and `i`ter_counts` in one go via `np.where`, ensuring that only the elements that haven't diverged (i.e., where the condition holds) are updated.\n\nBecause these operations — creating the grid, computing absolute values, applying the mask, and updating arrays — are all performed on entire arrays at once, they are handled in parallel by optimized C code under the hood. This eliminates the need for slow, explicit Python loops, which is why such an approach is highly efficient for intensive computations like generating the Mandelbrot set. The combination of vectorized operations and conditional updates not only makes the code concise but also allows the underlying hardware to execute many operations concurrently, resulting in much faster computation.\n\n### PyTorch\n\nNow let us do the same but with the `pytorch` library, except for the line `c = X.t() + 1j * Y.t()`, the code is identical to the `numpy` implementation. The `t()` function is used to transpose the matrix, and the `+` and `*` operators are overloaded to perform elementwise addition and multiplication, respectively. This allows us to create the complex grid `c` in a single line, just like in the `numpy` version.\n\n::: {.callout-note}\n## Tip\n\nThe reason you see a transpose in PyTorch is because its grid creation defaults to a different dimension ordering than `numpy`'s. In `numpy`, when you use `np.meshgrid` with `indexing='xy'`, the resulting arrays have the first dimension corresponding to the y-axis and the second to the x-axis, matching common image coordinate conventions. `pytorch`'s `torch.meshgrid`, on the other hand, typically returns tensors where the dimensions are swapped relative to that layout. By transposing (`.t()`) the `pytorch` tensors, you align the dimensions so that the complex grid `c` ends up with the same arrangement as in `numpy`. This ensures that each element in `c` correctly corresponds to the intended coordinate in the complex plane.\n:::\n\n::: {#b8cd3dee .cell execution_count=4}\n``` {.python .cell-code}\nimport torch\n\ndef compute_mandelbrot_torch(width:int = 500, height:int = 500, max_iter:int = 30, device:str = 'cpu') -> torch.Tensor:\n    real = torch.linspace(-2, 1, steps=width, device=device)\n    imag = torch.linspace(-1.5, 1.5, steps=height, device=device)\n    X, Y = torch.meshgrid(real, imag, indexing='xy')\n    c = X.t() + 1j * Y.t()\n    \n    z = torch.zeros_like(c)\n    iter_counts = torch.zeros(c.shape, device=device, dtype=torch.int32)\n    \n    for _ in range(max_iter):\n        mask = torch.abs(z) < 4\n        if not mask.any():\n            break\n        \n        z = torch.where(mask, z * z + c, z)\n        iter_counts = torch.where(mask, iter_counts + 1, iter_counts)\n    \n    return iter_counts\n```\n:::\n\n\nBecause we are using `pytorch` tensors, we can offload the workload onto a GPU by setting the `device` parameter to `'cuda'` or `'mps'`. This tells `pytorch` to use the GPU for all subsequent operations, which will significantly speed up the computation. The rest of the code remains the same, with the same vectorized operations and conditional updates as in the NumPy version.\n\nThe difference being that when using the GPU, the operations will run concurrently on the GPU cores, which are optimized for parallel computation. For example, when running `z = torch.where(mask, z * z + c, z)` on a GPU, each element in `z`, `mask`, and `c` can be processed simultaneously by different cores, allowing for massive speedups compared to sequential execution on a CPU. Effectivelly we will be \"painting\" the Mandelbrot set in one single operation rather than pixel by pixel.\n\n### Apple's MLX\n\nApple's MLX offers an API which is virtually the same as PyTorch and NumPy, and it can be used interchangeably with them. The only difference is that it is optimized for Apple hardware, and it can be used on Apple Silicon.\n\n::: {#eab842b5 .cell execution_count=5}\n``` {.python .cell-code}\nimport mlx.core as mx\n\ndef compute_mandelbrot_mlx(width:int = 500, height:int = 500, max_iter:int = 30) -> mx.array:\n    real = mx.linspace(-2, 1, width)\n    imag = mx.linspace(-1.5, 1.5, height)\n    X, Y = mx.meshgrid(real, imag, indexing='xy')\n    c = X + 1j * Y\n\n    z = mx.zeros_like(c)\n    iter_counts = mx.zeros(c.shape, dtype=mx.int32)\n\n    for _ in range(max_iter):\n        mask = mx.abs(z) < 4\n        if not mask.any():\n            break\n\n        z = mx.where(mask, z * z + c, z)\n        iter_counts = mx.where(mask, iter_counts + 1, iter_counts)\n\n    return iter_counts\n```\n:::\n\n\n## Putting it all together\n\nLet's put all the above together and render the Mandelbrot set with each different method. Each of `compute_mandelbrot_*` returns a 2D array of integers, where each integer represents the number of iterations it took for that pixel to diverge. We will then use `matplotlib` to render the image.\n\n::: {#9f10a0d6 .cell execution_count=6}\n``` {.python .cell-code}\nmps_available = torch.backends.mps.is_available()\n\nwidth, height = 500, 500\nmax_iter = 30\n\niter_counts = []\n\niter_counts_iterations = compute_mandelbrot_iterations(width, height, max_iter)\niter_counts.append(iter_counts_iterations)\niter_counts_numpy = compute_mandelbrot_numpy(width, height, max_iter)\niter_counts.append(iter_counts_numpy)\niter_counts_torch_cpu = compute_mandelbrot_torch(width, height, max_iter, \"cpu\")\niter_counts.append(iter_counts_torch_cpu.T.cpu())\nif mps_available:\n    iter_counts_torch_mps = compute_mandelbrot_torch(width, height, max_iter, \"mps\")\n    iter_counts.append(iter_counts_torch_mps.T.cpu())\niter_counts_mlx = compute_mandelbrot_mlx(width, height, max_iter)\niter_counts.append(iter_counts_mlx)\n```\n:::\n\n\n## Plotting the set\n\nNow let's create a function to plot the above `iter_counts` list of Mandelbrot images so we can compare each visually, they should all look the same.\n\n::: {#47ba4c8c .cell execution_count=7}\n``` {.python .cell-code}\nimport math\nimport matplotlib.pyplot as plt\n\ndef plot_mandelbrot_grid(iter_counts_list:list, titles:list = None):\n    n = len(iter_counts_list)\n    if n == 0:\n        print(\"No Mandelbrot sets to plot.\")\n        return\n\n    # Determine grid dimensions (roughly square)\n    n_cols = math.ceil(math.sqrt(n))\n    n_rows = math.ceil(n / n_cols)\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2.5 * n_cols, 2.5 * n_rows))\n    \n    # Flatten axes array for easier iteration\n    if n == 1:\n        axes = [axes]\n    else:\n        axes = axes.flatten()\n    \n    for i, (ax, counts) in enumerate(zip(axes, iter_counts_list)):\n        ax.imshow(counts, cmap='plasma', interpolation='nearest', origin='lower')\n        # Use provided title if available, else default to \"Mandelbrot\"\n        title = titles[i] if titles is not None and i < len(titles) else \"Mandelbrot\"\n        # Add title text inside the plot at the top-left corner\n        ax.text(0.05, 0.95, title, transform=ax.transAxes, \n                color='white', fontsize=14, verticalalignment='top',\n                bbox=dict(facecolor='black', alpha=0.5, edgecolor='none'))\n        ax.axis('off')\n    \n    # Hide any unused subplots\n    for ax in axes[n:]:\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n```\n:::\n\n\n::: {#d4fa6b04 .cell execution_count=8}\n``` {.python .cell-code}\nplot_mandelbrot_grid(\n    iter_counts,\n    titles=[\n        \"Python (iterations)\",\n        \"NumPy\",\n        \"PyTorch (CPU)\",\n        \"PyTorch (MPS)\" if mps_available else None, \"Apple MLX\"\n    ]\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\nThat confirms that each of the methods above is correct, and that they all yield the same result. The only difference is the speed at which they compute the Mandelbrot set!\n\n## Timing the functions\n\nSo we can easily contrast and compare the speed of each of the above functions, let's time them using the `time` module in Python at different resolutions (width and height). We will see the difference in parallelism between methods which rely entirely on the CPU and those which offload the computation to the GPU. All timings are in seconds.\n\n::: {#b334194e .cell execution_count=9}\n``` {.python .cell-code}\nimport time\n\nresolutions = [1000, 2000, 3000, 4000]\nmax_iter = 1000\n\nheader = [\n    \"Resolution\",\n    \"Iterations\",\n    \"NumPy\",\n    \"PyTorch/cpu\",\n    \"PyTorch/mps\", \n    \"MLX\"\n]\n\ntable_data = []\n\nfor n in resolutions:\n    width = height = n\n    timings = {}\n    \n    start_time = time.time()\n    compute_mandelbrot_iterations(width, height, max_iter)\n    timings[\"Iterations\"] = time.time() - start_time\n\n    start_time = time.time()\n    compute_mandelbrot_numpy(width, height, max_iter)\n    timings[\"NumPy\"] = time.time() - start_time\n\n    start_time = time.time()\n    compute_mandelbrot_torch(width, height, max_iter, \"cpu\")\n    timings[\"PyTorch/cpu\"] = time.time() - start_time\n\n    if mps_available:\n        start_time = time.time()\n        compute_mandelbrot_torch(width, height, max_iter, \"mps\")\n        timings[\"PyTorch/mps\"] = time.time() - start_time\n    else:\n        timings[\"PyTorch/mps\"] = None\n\n    start_time = time.time()\n    compute_mandelbrot_mlx(width, height, max_iter)\n    timings[\"MLX\"] = time.time() - start_time\n\n    row = [\n        f\"{n}x{n}\",\n        f\"{timings['Iterations']:.3f}\",\n        f\"{timings['NumPy']:.3f}\",\n        f\"{timings['PyTorch/cpu']:.3f}\",\n        f\"{timings['PyTorch/mps']:.3f}\" if timings['PyTorch/mps'] is not None else \"N/A\",\n        f\"{timings['MLX']:.3f}\"\n    ]\n    table_data.append(row)\n\nprint(\"{:<12} {:<12} {:<12} {:<15} {:<15} {:<12}\".format(*header))\nfor row in table_data:\n    print(\"{:<12} {:<12} {:<12} {:<15} {:<15} {:<12}\".format(*row))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResolution   Iterations   NumPy        PyTorch/cpu     PyTorch/mps     MLX         \n1000x1000    19.987       5.667        2.689           0.514           0.394       \n2000x2000    80.211       27.019       5.356           1.546           1.391       \n3000x3000    175.523      68.376       17.918          3.094           2.884       \n4000x4000    312.880      124.933      31.909          5.266           4.755       \n```\n:::\n:::\n\n\nAnd finally let us put the above results in an intuitive visual representation, so we can see the difference in speed between the different methods.\n\n::: {#b1ebaf4b .cell execution_count=10}\n``` {.python .cell-code}\nimport matplotlib.ticker as ticker\n\nresolutions_numeric = [int(row[0].split('x')[0]) for row in table_data]\nmethods = header[1:]\n\nnum_res = len(resolutions_numeric)\nnum_methods = len(methods)\nx = np.arange(num_res)  # x locations for the groups\nwidth = 0.15            # width of each bar\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot bars for each method\nfor i, method in enumerate(methods):\n    times = []\n    for row in table_data:\n        value = row[i+1]  # skip the resolution column\n        # Use 0 for \"N/A\", or you could choose to skip/handle it differently\n        times.append(float(value) if value != \"N/A\" else 0)\n    # Calculate offset for each method within the group\n    offset = (i - num_methods/2) * width + width/2\n    ax.bar(x + offset, times, width, label=method)\n\n# Set labels and ticks\nax.set_xlabel(\"Resolution (pixels)\")\nax.set_ylabel(\"Time (s)\")\nax.set_xticks(x)\nax.set_xticklabels([f\"{res}x{res}\" for res in resolutions_numeric])\n\n# Disable scientific notation on the y-axis\nformatter = ticker.ScalarFormatter()\nformatter.set_scientific(False)\nax.yaxis.set_major_formatter(formatter)\n\nax.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\nYou can see that GPU methods are significantly faster than the CPU because of its inherent parallelism. The more cores you have, the faster the computation will be. This is why GPUs are so good at parallel workloads, and why they are so adept to machine learning and AI workloads - deep down, they are just matrix operations using embarrasingly parallel workloads.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}