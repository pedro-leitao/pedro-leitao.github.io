{
  "hash": "97a2e9037a99c60416d9e24915e893f5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'The Basics of Unsupervised Learning: Segmenting an Image'\nsubtitle: a quick primer on what unsupervised learning means and how it can be used for image segmentation\ndate: 2024-06-07\ntags: \n  - Experiments\n  - Machine Learning\n  - Unsupervised Learning\n  - Image Segmentation\n  - K-means Clustering\ncategories:\n  - Experiments\n  - Machine Learning\n  - Unsupervised Learning\njupyter: python3\n---\n\n\n\nUnsupervised learning is a type of machine learning that looks for previously undetected patterns in a dataset without pre-existing labels and with minimal human supervision. Unlike supervised learning, where the model is trained on labeled data, unsupervised learning works on its own to identify structures and patterns within the data. This makes it particularly useful in situations where labeled data is scarce or unavailable.\n\nOne common example of unsupervised learning is clustering, which involves grouping data points into clusters based on their similarities. A widely used algorithm for clustering is k-means, which partitions the data into $\\mathbf{k}$ clusters, each represented by a centroid. Applications of clustering include customer segmentation, image segmentation, and biological data analysis.\n\nAnother example is anomaly detection, which identifies rare items, events, or observations that raise suspicions by differing significantly from the majority of the data. Anomaly detection is used in various fields such as fraud detection in finance, network security for identifying intrusions, and fault detection in industrial systems.\n\nDimensionality reduction is also a key technique in unsupervised learning. It reduces the number of random variables under consideration by obtaining a set of principal variables. Techniques like [Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE)](pca-vs-tsne) simplify models, reduce computation time, and visualize high-dimensional data. Dimensionality reduction is widely used in data preprocessing, image compression, and noise reduction.\n\nOther applications of unsupervised learning include association rule learning, which discovers interesting relations between variables in large databases. This method is commonly used in market basket analysis to find sets of products that frequently co-occur in transactions. Feature learning is another application where representations or features from raw data that are useful for machine learning tasks are automatically discovered. Techniques like autoencoders and generative adversarial networks (GANs) are used for tasks such as image generation, speech synthesis, and data denoising.\n\nHierarchical clustering is another form of unsupervised learning that builds a tree of clusters, unlike k-means, which requires a predefined number of clusters. This method is particularly useful for discovering hierarchical relationships in data, such as taxonomies in biology.\n\nUnsupervised learning is crucial in exploratory data analysis, where insights and patterns need to be uncovered without prior knowledge. It helps in understanding the underlying structure of the data, leading to more informed decisions and better data-driven strategies.\n\nIn this experiment, we will explore the basics of unsupervised learning by segmenting an image using k-means clustering. We will identify distinct regions in the image, and assign each pixel to a cluster based on its color similarity. This technique is commonly used in image processing for tasks like object detection, image compression, and image segmentation.\n\n\n## Generating a synthetic landscape\n\nLet's start by generating a synthetic landscape image that we will use for segmentation. To do so, we will create a simple 512x512 \"virtual\" landscape of different \"heights\" between 0 and 1.\n\n::: {#86bf3f92 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom noise import pnoise2\nfrom PIL import Image\nfrom skimage.measure import find_contours\n\ndef generate_procedural_landscape(size=256, scale=100.0, octaves=6, persistence=0.5, lacunarity=2.0, seed=0):\n    \"\"\"\n    Generate a procedural landscape with hills and valleys using Perlin noise.\n    \n    :param size: The size of the landscape (size x size).\n    :param scale: The scale of the noise.\n    :param octaves: Number of layers of noise.\n    :param persistence: Amplitude of each octave.\n    :param lacunarity: Frequency of each octave.\n    :param seed: The seed for generating different landscapes.\n    :return: A 2D numpy array representing the landscape heights.\n    \"\"\"\n    landscape = np.zeros((size, size))\n    \n    for i in range(size):\n        for j in range(size):\n            x = (i + seed) / scale\n            y = (j + seed) / scale\n            landscape[i][j] = pnoise2(x, y, octaves=octaves, persistence=persistence, lacunarity=lacunarity)\n    \n    # Normalize the values to be between 0 and 1\n    min_val = np.min(landscape)\n    max_val = np.max(landscape)\n    landscape = (landscape - min_val) / (max_val - min_val)\n    \n    return landscape\n```\n:::\n\n\n::: {#66aed1b9 .cell execution_count=3}\n``` {.python .cell-code}\nlandscape = generate_procedural_landscape(size=512, scale=128)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(landscape, cmap='terrain')\nplt.title('Procedural Landscape')\nplt.colorbar()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\nWe have a simple image, where the pixel intensity represents the height of the landscape. To make it visually intuitive to understand what we are doing, let us identify and visualise isolines of different heights. Isolines are lines that connect points of equal value, such as points of equal height in a landscape.\n\n::: {#1a0e3bc1 .cell execution_count=4}\n``` {.python .cell-code}\ndef landscape_isocontour(landscape, thresholds=[0.3, 0.5, 0.7]):\n    \"\"\"\n    Generate iso-contour lines for the landscape.\n    \n    :param landscape: A 2D numpy array representing the landscape heights.\n    :param thresholds: List of threshold values for the isocontours.\n    :return: A list of contour arrays.\n    \"\"\"\n    contours = []\n    for threshold in thresholds:\n        contour = find_contours(landscape, level=threshold)\n        contours.append(contour)\n    return contours\n```\n:::\n\n\n::: {#9920f718 .cell execution_count=5}\n``` {.python .cell-code}\n# Generate isocontours for the landscape\ncontours = landscape_isocontour(landscape, thresholds=[0.3, 0.5, 0.7])\n\n# Plot the landscape with isocontours\nplt.figure(figsize=(6, 6))\nplt.imshow(landscape, cmap='terrain')\nplt.title('Procedural Landscape with Isocontours')\nplt.colorbar()\nfor contour in contours:\n    for line in contour:\n        plt.plot(line[:, 1], line[:, 0], linewidth=2)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nThat looks interesting. What we ultimately are trying to synthethise is something which looks like a satellite view of a natural landscape. To do this, let us take this height representation, and convert it into a color representation where low lying areas are blue (water), high lying areas are white (snow), and everything in between is green (grass) or brown (mountains). To do so, we will apply a color map to the height representation, and interpolate between colors to create gradients representing intermediate areas.\n\n::: {#e5c0b22f .cell execution_count=6}\n``` {.python .cell-code}\ndef lerp(color1, color2, t):\n    \"\"\"\n    Linearly interpolate between two colors.\n    \n    :param color1: The first color (as an array of [R, G, B]).\n    :param color2: The second color (as an array of [R, G, B]).\n    :param t: The interpolation parameter (0 <= t <= 1).\n    :return: The interpolated color.\n    \"\"\"\n    return (1 - t) * np.array(color1) + t * np.array(color2)\n\ndef apply_colormap(landscape,\n                   water_color=[20, 20, 220],\n                   grass_color=[20, 220, 20],\n                   mountain_color=[139, 69, 19],\n                   snow_color=[220, 220, 220],\n                   transition_width=0.05,\n                   water_threshold=0.4,\n                   grass_threshold=0.6,\n                   mountain_threshold=0.8):\n    \"\"\"\n    Apply a colormap to the landscape to simulate various elements (e.g., water, grass, mountains, snow) with soft edges.\n    \n    :param landscape: A 2D numpy array representing the landscape heights.\n    :return: A 3D numpy array with RGB values.\n    \"\"\"\n    \n    # Create an RGB image\n    rgb_image = np.zeros((landscape.shape[0], landscape.shape[1], 3), dtype=np.uint8)\n    \n    # Apply colors based on thresholds with gradients\n    for i in range(landscape.shape[0]):\n        for j in range(landscape.shape[1]):\n            height = landscape[i, j]\n            \n            if height < water_threshold - transition_width:\n                rgb_image[i, j] = water_color\n            elif height < water_threshold + transition_width:\n                t = (height - (water_threshold - transition_width)) / (2 * transition_width)\n                rgb_image[i, j] = lerp(water_color, grass_color, t)\n            elif height < grass_threshold - transition_width:\n                rgb_image[i, j] = grass_color\n            elif height < grass_threshold + transition_width:\n                t = (height - (grass_threshold - transition_width)) / (2 * transition_width)\n                rgb_image[i, j] = lerp(grass_color, mountain_color, t)\n            elif height < mountain_threshold - transition_width:\n                rgb_image[i, j] = mountain_color\n            elif height < mountain_threshold + transition_width:\n                t = (height - (mountain_threshold - transition_width)) / (2 * transition_width)\n                rgb_image[i, j] = lerp(mountain_color, snow_color, t)\n            else:\n                rgb_image[i, j] = snow_color\n    \n    return rgb_image\n\ndef landscape_as_image(landscape, transition_width=0.1):\n    \"\"\"\n    Save the procedural landscape as a colorful image file.\n    \n    :param landscape: A 2D numpy array representing the landscape heights.\n    :param filename: The filename to save the image as.\n    \"\"\"\n    # Apply the colormap\n    rgb_image = apply_colormap(landscape, transition_width=transition_width)\n    \n    # Create an image object\n    image = Image.fromarray(rgb_image, mode='RGB')\n    \n    return image\n```\n:::\n\n\n::: {#997a5397 .cell execution_count=7}\n``` {.python .cell-code}\n# Convert the landscape to an image which represents different elements, such as water, grass, mountains, and snow\nlandscape_image = landscape_as_image(landscape, transition_width=0.06)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(landscape_image)\nplt.title('Procedural Landscape with Colormap')\nplt.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\nNow we got somewhere! We have a synthetic landscape image that we can use for segmentation. Let's move on to the next step.\n\n::: {.callout-note}\nAs an exercise, you could replace this synthetic landscape with a real satellite image and apply the same techniques to segment it. A good place to start is [Skywatch](https://explore.skywatch.com/), which provides access to both free and commercial satellite imagery for various applications.\n:::\n\n## Segmentation using k-means clustering\n\nNow that we have our synthetic landscape, we will segment it using k-means clustering. The goal is to group pixels with similar colors together, forming distinct regions in the image. k-means clustering is an iterative algorithm that partitions the data into $\\mathbf{k}$ clusters based on the similarity of their features. In our case, the features are the RGB values of each pixel.\n\n::: {#bc30aac8 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\n\ndef classify_image(image, n_clusters=10):\n    \"\"\"\n    Classify the image into regions using K-means clustering.\n    \n    :param image_np: A numpy array representing the image.\n    :param n_clusters: The number of clusters to classify into.\n    :return: A 2D numpy array with cluster labels and the cluster centers as RGB values.\n    \"\"\"\n    # Convert the image to a numpy array\n    image_np = np.array(image)\n\n    # Reshape the image to a list of pixels\n    pixels = image_np.reshape(-1, 3)\n    \n    # Perform K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(pixels)\n    \n    # Get the cluster labels and centers\n    labels = kmeans.labels_\n    centers = kmeans.cluster_centers_\n    \n    # Reshape the labels back to the original image shape\n    classified_image = labels.reshape(image_np.shape[:2])\n    \n    return classified_image, centers\n```\n:::\n\n\n::: {#a8d0aa27 .cell execution_count=9}\n``` {.python .cell-code}\n# Classify the image using K-means clustering\n\nclassified_image, centers = classify_image(landscape_image, n_clusters=7)\n\n# Show the classified image, with a symbolic colormap, include a legend with the cluster centers\nplt.figure(figsize=(6, 6))\nplt.imshow(classified_image, cmap='tab10')\nplt.title('Classified Landscape')\nplt.axis('off')\n\n# Get the colormap colors for the legend\ncolormap = plt.get_cmap('tab10')\ncolors = [colormap(i) for i in range(len(centers))]\n\nplt.legend(handles=[plt.Line2D([0], [0], \n                               marker='o',\n                               color='w',\n                               label=f'Cluster {i}', markerfacecolor=colors[i]) for i in range(len(centers))], loc='upper right',\n                               bbox_to_anchor=(1, 1))\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){}\n:::\n:::\n\n\nWhat you see is a segmented image where each color represents a different cluster. The algorithm has grouped pixels with similar colors together, creating distinct regions in the image. The image has been painted with a color palette that represents the different clusters identified by the algorithm, and which do not necessarily correspond to the original colors of the landscape.\n\nLet us now turn the classification into a segmented image, where each pixel is colored back according to the type of landscape the cluster represents. This will give us a visual representation of the segmentation results which is close to the original image (think of it as a \"paint by numbers\" exercise which will eliminate the gradient colors). We do this by replacing the RGB values of each pixel with the centroid of the cluster it belongs to.\n\n::: {#433d0ba9 .cell execution_count=10}\n``` {.python .cell-code}\nfrom scipy.spatial.distance import cdist\n\n\n# Define color dictionary for the colormap\ncolor_dict = {\n    'water': [20, 20, 220],     # Blue for water\n    'grass': [20, 255, 20],     # Green for grass\n    'mountains': [139, 69, 19], # Brown for mountains\n    'snow': [220, 220, 220]     # White for snow\n}\n# Define target colors for each landscape element\ntarget_colors = np.array([\n    color_dict['water'],\n    color_dict['grass'],\n    color_dict['mountains'],\n    color_dict['snow']])\n\ndef segment_with_colormap(classified_image, centers):\n    \"\"\"\n    Apply a colormap to the classified image.\n    \n    :param classified_image: A 2D numpy array with cluster labels.\n    :param centers: The cluster centers.\n    :return: A 3D numpy array with RGB values.\n    \"\"\"\n    \n    # Match the cluster centers to the target colors\n    distances = cdist(centers, target_colors)\n    closest_colors = np.argmin(distances, axis=1)\n    \n    # Create an RGB image\n    rgb_image = np.zeros((classified_image.shape[0], classified_image.shape[1], 3), dtype=np.uint8)\n    \n    for cluster_label in range(len(centers)):\n        rgb_image[classified_image == cluster_label] = target_colors[closest_colors[cluster_label]]\n    \n    return rgb_image, closest_colors\n```\n:::\n\n\n::: {#33526d17 .cell execution_count=11}\n``` {.python .cell-code}\n# Apply the cluster colormap to the classified image\nsegmented_image, closest_colors = segment_with_colormap(classified_image, centers)\n\n# Show the original image and the cluster-colored image\nfig, ax = plt.subplots(1, 2, figsize=(8, 6))\nax[0].imshow(landscape_image)\nax[0].set_title('Original Image')\nax[0].axis('off')\nax[1].imshow(segmented_image)\nax[1].set_title('Segmented Image')\nax[1].axis('off')\n# Create a legend\nhandles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=target_colors[i]/255, markersize=10) for i in range(len(target_colors))]\nlabels = color_dict.keys()\nax[1].legend(handles, labels, loc='upper right', bbox_to_anchor=(1, 1))\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){}\n:::\n:::\n\n\nThat's starting to make sense. We now have a segmented image that represents the different regions in the landscape. Each pixel has been assigned to a cluster based on its color similarity and colored according to the centroid of the cluster. This process has created distinct regions in the image, making it easier to identify different parts of the landscape. This technique is commonly used in image processing for tasks like object detection, where the goal is to locate and identify objects within an image. By segmenting the image into different regions, it's possible to isolate areas of interest and perform further analysis on them.\n\nIn addition to object detection, image segmentation is also used in medical imaging to identify and delineate structures within the body, such as organs, tissues, and tumors. This helps doctors and radiologists in diagnosing diseases and planning treatments. In satellite and aerial imagery, segmentation helps in classifying land cover types, such as urban areas, forests, and bodies of water, aiding in environmental monitoring and urban planning. Another application of image segmentation is in autonomous driving, where it is essential to recognize and understand various elements of the road environment, including vehicles, pedestrians, road signs, and lane markings. By segmenting the image, autonomous vehicles can make better decisions and navigate more safely.\n\nIt is also crucial in the field of computer vision for applications such as facial recognition, where different parts of the face are segmented to extract features like eyes, nose, and mouth. This improves the accuracy of recognition systems and enables more advanced functionalities like emotion detection. This kind of analysis serves as a foundational technique in many areas of image processing and computer vision, enabling more precise and efficient analysis of visual data. By breaking down an image into meaningful segments, we can gain deeper insights and develop more advanced algorithms for a wide range of applications.\n\nBack to clustering, we should also mention that the number of clusters $\\mathbf{k}$ is a hyperparameter that needs to be tuned based on the data and the desired level of granularity. Choosing the right number of clusters is essential for obtaining meaningful results and avoiding overfitting or underfitting. Techniques like the elbow method, silhouette score, and cross-validation can help in determining the optimal number of clusters for a given dataset.\n\n::: {.callout-note}\n## About the Elbow Method\n\nThe elbow method is a technique used to determine the optimal number of clusters in a dataset for k-means clustering. It involves running k-means clustering on the dataset for a range of values for $\\mathbf{k}$ (the number of clusters) and then plotting the within-cluster sum of squares ($\\mathbf{WCSS}$) against the number of clusters. The $\\mathbf{WCSS}$ measures the sum of the squared distances between each data point and the centroid of the cluster it belongs to, serving as a measure of the compactness of the clusters; lower $\\mathbf{WCSS}$ values indicate more compact clusters.\n\nThe critical step is identifying the point where the rate of decrease in $\\mathbf{WCSS}$ slows down significantly, known as the \"elbow.\" This point indicates that increasing the number of clusters beyond this point does not significantly improve the compactness of the clusters, suggesting that the optimal number of clusters has been reached. The elbow point represents a balance between having a low $\\mathbf{WCSS}$ and avoiding too many clusters, which could lead to overfitting.\n\nThe elbow method is a heuristic that can be useful in many situations, but it is not always definitive. In some cases, the elbow may not be clearly identifiable, or there may be multiple elbows, making it challenging to determine the optimal number of clusters. In such cases, other methods, such as the silhouette score or the gap statistic, can be used alongside the elbow method to validate the choice of $\\mathbf{k}$.\n:::\n\n### Determining the optimal number of clusters\n\nLet's visually compare the results of k-means clustering for different values of $\\mathbf{k}$ to determine the optimal number of clusters for our synthetic landscape image. We will run k-means clustering for $\\mathbf{k=2, 3, 4, 5, 6, 7, 8, 9, 10}$ and visualize the segmented images for each value of $\\mathbf{k}$, and visually compare.\n\n::: {#47d6111f .cell execution_count=12}\n``` {.python .cell-code}\n# Create a grid of classified images with different number of clusters\n\nn_clusters = 10\nfig = plt.figure(figsize=(8, 8))\nplt.suptitle('Classified Images with Different Number of Clusters', fontsize=12)\nfor i in range(2, n_clusters + 1):\n    _classified_image, _centers = classify_image(landscape_image, n_clusters=i)\n    _color_mapped_image, _ = segment_with_colormap(_classified_image, _centers)\n    \n    plt.subplot(3, 3, i - 1)\n    plt.imshow(_color_mapped_image)\n    plt.axis('off')\n    plt.title(f'{i} Clusters')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\nWe can see that as the number of clusters increases, the image becomes more finely segmented, capturing more detailed regions in the landscape. However, beyond a certain point, adding more clusters does not significantly improve the segmentation quality and may lead to overfitting. The optimal number of clusters depends on the desired level of granularity and the complexity of the image. Let us try the elbow method to determine the optimal number of clusters for our synthetic landscape image.\n\n::: {#95332c1f .cell execution_count=13}\n``` {.python .cell-code}\n# Calculate WCSS for different values of k\n\nwcss = []\nn_clusters_range = range(1, 11)\nfor i in n_clusters_range:\n    _, centers = classify_image(landscape_image, n_clusters=i)\n    pixels = np.array(landscape_image).reshape(-1, 3)\n    kmeans = KMeans(n_clusters=i, random_state=42)\n    kmeans.fit(pixels)\n    wcss.append(kmeans.inertia_)\n\n# Plot the WCSS values\nplt.figure(figsize=(8, 6))\nplt.plot(n_clusters_range, wcss, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\nIt looks like the optimal number of clusters for our synthetic landscape image is around $\\mathbf{k=4}$, as the rate of decrease in $\\mathbf{WCSS}$ slows down significantly after this point. We can use the \"knee\" method to mathematically determine the optimal number of clusters, but in practice, it is often a subjective decision based on the data and the desired level of granularity.\n\n::: {#c17ec770 .cell execution_count=14}\n``` {.python .cell-code}\nfrom kneed import KneeLocator\n\n# Find the \"elbow\" point\nkneedle = KneeLocator(n_clusters_range, wcss, curve='convex', direction='decreasing')\noptimal_n_clusters = kneedle.elbow\n\nprint(f'Optimal number of clusters: {optimal_n_clusters}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimal number of clusters: 4\n```\n:::\n:::\n\n\nWe were right in our initial assumption! The optimal number of clusters for our synthetic landscape image is indeed $\\mathbf{k=4}$ according to the knee method. Let us now look for the boundaries between the clusters to better understand the segmentation results. We will overlay the cluster boundaries on the segmented image to visualize the regions where the clusters meet.\n\n::: {#e5280510 .cell execution_count=15}\n``` {.python .cell-code}\nfrom skimage.segmentation import find_boundaries\n\ndef find_image_boundaries(classified_image):\n    \"\"\"\n    Find the boundaries of classified regions in the image and label them.\n    \n    :param classified_image: A 2D numpy array with cluster labels.\n    :param closest_colors: The mapped color labels for each cluster.\n    :return: A 2D numpy array with boundaries.\n    \"\"\"\n    boundaries = find_boundaries(classified_image, mode='thick')\n    return boundaries\n```\n:::\n\n\n::: {#13219c3b .cell execution_count=16}\n``` {.python .cell-code}\n# Find the boundaries in the classified image\nboundaries_image = find_image_boundaries(classified_image)\n\n# Plot the classified image overlayed with boundaries\nplt.figure(figsize=(6, 6))\nplt.imshow(landscape_image)\nplt.imshow(boundaries_image, alpha=0.5)\nplt.title('Classified Image with Boundaries')\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){}\n:::\n:::\n\n\n## Wraping it up\n\nWe have successfully segmented the synthetic landscape image using k-means clustering and visualized the results. The segmentation has created distinct regions in the image, making it easier to identify different parts of the landscape. By assigning each pixel to a cluster based on its color similarity, we have grouped pixels with similar colors together, forming meaningful segments in the image.\n \n To wrap things up, let us overlay everything with different landscape markers to map the different regions of the synthetic landscape image.\n\n::: {#04b8024f .cell execution_count=17}\n``` {.python .cell-code}\nfrom skimage.measure import regionprops, label\n\n# Define labels for each landscape element\nlabels_dict = {\n    0: 'Water',\n    1: 'Grass',\n    2: 'Mountain',\n    3: 'Snow'\n}\n\n# Display boundaries image\nplt.figure(figsize=(6, 6))\nplt.imshow(landscape_image)\nplt.imshow(boundaries_image, alpha=0.5)\nplt.title('Classified Image with Boundaries and Markers')\nplt.axis('off')\n\n# Use regionprops to find centroids of each region and add one label per class\nlabeled_array, num_features = label(classified_image, return_num=True)\nprops = regionprops(labeled_array)\n\n# Define symbols for each landscape element\nsymbols_dict = {\n    0: ('o', 'water'),\n    1: ('s', 'grass'),\n    2: ('^', 'mountain'),\n    3: ('p', 'snow')\n}\n\n# To avoid duplicate labels in the legend\nhandles = {}\n\nfor prop in props:\n    y, x = prop.centroid\n    label_index = classified_image[int(y), int(x)]\n    symbol, label_text = symbols_dict.get(closest_colors[label_index], ('x', 'Unknown'))\n    scatter = plt.scatter(x, y, marker=symbol, color='salmon', s=100, edgecolor='black', label=label_text)\n    \n    # Add to handles only if label_text not already added\n    if label_text not in handles:\n        handles[label_text] = scatter\n\n# Create a legend\nplt.legend(handles=handles.values(), labels=handles.keys(), loc='upper right')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){}\n:::\n:::\n\n\n## Final remarks\n\nUnsupervised methods like k-means group similar pixels, creating meaningful image segments for further analysis. Image segmentation is crucial in areas like object detection, medical imaging, satellite imagery, and autonomous driving.\n\nBeyond k-means, hierarchical clustering reveals nested clusters without a preset number, DBSCAN handles noise and arbitrary shapes, and Gaussian Mixture Models allow soft clustering based on probabilistic distributions. Dimensionality reduction (PCA, autoencoders, t-SNE, Self-Organizing Maps) helps visualize high-dimensional data and extract features. GANs, while mainly for realistic data generation, also support tasks like anomaly detection and semi-supervised learning.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}