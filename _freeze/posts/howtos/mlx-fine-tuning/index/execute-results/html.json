{
  "hash": "5f4a117bfb7ed6d53952ee963c9edd37",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Fine-tuning an LLM with Apple's MLX Framework\nsubtitle: fine-tuning pre-trained language models in apple silicon\ndate: 2024-12-11\ntags: \n  - HowTo\n  - AI\n  - MLX\n  - Fine-tuning\n  - Language Models\ncategories:\n  - HowTo\n  - AI\n  - Language Models\njupyter: python3\n---\n\n\nModern GPU's come with inbuilt memory, which is separate from the CPU's memory. This means that when training large models, the data has to be copied from the CPU's memory to the GPU's memory, which can be slow and inefficient. This is particularly problematic when training large language models (LLM's), as the data can be too large to fit into the GPU's memory.\n\nWith Apple Silicon, the emergence of shared memory between the CPU and GPU has opened up a lot of possibilities for machine learning, as the GPU can now access the CPU's memory directly. This is a huge advantage for training large models, as it removes the GPU RAM limitation, even if the GPU itself is not as powerful as a dedicated GPU.\n\n\n```{mermaid}\n\nflowchart TD\n    classDef cpu fill:#b3d9ff,stroke:#333\n    classDef gpu fill:#ffb3b3,stroke:#333\n    classDef ne fill:#b3ffb3,stroke:#333\n    classDef other fill:#ffffb3,stroke:#333\n    classDef uma fill:#e6f2ff,stroke:#333\n    classDef features fill:#f0f0f0,stroke:#333\n\n    CPU(\"CPU Cores\"):::cpu <--> UMA\n    GPU(\"GPU Cores\"):::gpu <--> UMA\n    NE(\"Neural Engine\"):::ne <--> UMA\n    UMA([\"Unified Memory Pool<br>(VRAM)\"]):::uma\n```\n\n\nApple also released the [MLX framework](https://opensource.apple.com/projects/mlx/), which is Apple's take on PyTorch and NumPy, but taking full advantage of the Unified Memory Architecture (UMA) of Apple Silicon.\n\nHere we will see how we can fine-tune a pre-trained LLM using the MLX framework, using the LoRA approach.\n\n::: {.callout-note}\n## About LoRA\n\n[LoRA](https://arxiv.org/abs/2106.09685) (Low-Rank Adaptation) is a technique for fine-tuning large machine learning models, like language models or image generators, without retraining the entire model from scratch. Instead of updating all the model’s parameters—which can be slow, expensive, and require massive computational resources—LoRA freezes the original model and adds small, trainable \"adapters\" to specific parts of the network (like the attention layers in a transformer model). These adapters are designed using low-rank matrices, which are pairs of smaller, simpler matrices that approximate how the original model’s weights would need to change for a new task.\n\nThe core idea is to avoid retraining a massive neural network with billions of parameters for every new task, such as adapting to a specialized domain or style. LoRA modifies only a tiny fraction of the model by training two smaller matrices for each targeted layer. These matrices work together to capture the most important adjustments needed for the task. The size of these matrices is controlled by a \"rank\" hyperparameter, which balances efficiency and accuracy. This approach reduces the number of trainable parameters by thousands of times, making fine-tuning feasible on hardware with limited resources.\n\nOnce trained, the adapter matrices can be merged back into the original model during inference, adding almost no computational overhead. This makes the adapted model as fast as the original during deployment. The benefits include significant memory and computational savings, flexibility in training multiple lightweight adapters for different tasks (e.g., coding, translation, or art styles), and performance that often matches full fine-tuning. By focusing on low-rank updates, LoRA efficiently captures critical task-specific adjustments without altering the bulk of the pre-trained model’s knowledge.\n:::\n\n\n```{mermaid}\n\ngraph LR\n    subgraph Input Layer\n        A1((Input))\n    end\n\n    subgraph Hidden Layer 1\n        B1((\"Layer Parameters\"))\n    end\n\n    subgraph Hidden Layer 2\n        C1((\"Layer Parameters\"))\n    end\n\n    subgraph Output Layer\n        D1((Output))\n    end\n\n    %% LoRA Additions (colored differently)\n    L1((\"LoRA Adapter\")):::loraStyle\n    L2((\"LoRA Adapter\")):::loraStyle\n\n    %% Connections in Pre-trained Model\n    A1 --> B1\n    B1 --> C1\n    C1 --> D1\n\n    %% LoRA Connections (colored differently)\n    L1 --> B1:::loraConnection\n    L2 --> C1:::loraConnection\n\n    %% Style Definitions\n    classDef loraStyle fill:#f9d5e5,stroke:#c81d7a,stroke-width:2px,color:#000;\n    classDef loraConnection stroke:#c81d7a,stroke-width:2px,stroke-dasharray:5 5;\n```\n\n\n## A brief overview of fine-tuning\n\nFine-tuning a pre-trained language model is common practice. The idea is to take a pre-trained model, like Llama or Qwen, and train on a specific dataset to adapt it to a specific task. This is typically done by freezing the weights of the pre-trained model and adding a small number of trainable parameters to the model, which are trained on the new dataset.\n\nOverall, there are three main ways to fine-tune a pre-trained model:\n\n- **Full fine-tuning**: In this approach, all the weights of the pre-trained model are unfrozen, and the entire model is trained on the new dataset. This is the most computationally expensive approach, as it requires training the entire model from scratch.\n- **Layer-wise fine-tuning**: Only a subset of the layers in the pre-trained model are unfrozen and trained on the new dataset. This is less computationally expensive than full fine-tuning, as only a portion of the model is trained.\n- **Adapter-based fine-tuning**: Small trainable \"adapters\" are added to specific parts of the pre-trained model, and only these adapters are trained on the new dataset. This is the least computationally expensive approach, as only a small number of parameters are trained (this is the LoRA approach).\n\nAdditionally, there are two main types of fine-tuning based on supervision:\n\n- **Unsupervised fine-tuning**: In this approach, the pre-trained model is fine-tuned on a new dataset without any labels (which is to say, we give the model a large amount of content). In other words, we offer the model a new corpus of text, and the model learns to generate text in the style of the new corpus.\n- **Supervised fine-tuning**: The pre-trained model is fine-tuned on a new dataset with labels. That is, we offer the model a new corpus of text (\"prompts\") with labels (the \"output\"), and the model learns to generate text that matches the intended labels.\n\nMLX can handle any combination of the above.\n\n## Starting with the MLX framework\n\nTo begin, we need to install the MLX framework on your Apple Silicon Mac. MLX is a Python library, so we can install it in a variety of ways depending on your Python environment, for example, for Conda:\n\n\n```{bash}\nconda install -c conda-forge mlx mlx-lm\n```\n\n\nOr with `pip`:\n\n\n```{bash}\npip install mlx mlx-lm\n```\n\n\nOnce installed, you will have available the basic set of MLX tools, including the `mlx` command-line tool, which can be used to create new projects, run experiments, and manage datasets.\n\nMLX can directly download models from the Hugging Face model hub - just keep in mind that not all models are optimized for the MLX framework. You can [find many MLX optimized models](https://huggingface.co/models?library=mlx&sort=trending), and there is an [active community](https://huggingface.co/mlx-community) working on adding more to the list.\n\nAs an example, let's generate some text using a very small [Qwen](https://github.com/QwenLM/Qwen) model with just $1/2$ billion parameters and 8 bit quantization:\n\n\n```{bash}\nmlx_lm.generate \\\n    --model lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit \\\n    --prompt 'When did Michael Jackson die?'\n```\n\n\nIn my case, I use [LMStudio](https://lmstudio.ai) to manage models, so I point at the model in a specific location rather than downloading it from the Hugging Face model hub via the `mlx` command.\n\n::: {#b1ece29e .cell execution_count=2}\n``` {.python .cell-code}\n!mlx_lm.generate \\\n    --model $HOME/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit \\\n    --prompt 'When did Michael Jackson die? Stick to facts.' \\\n    --max-tokens 256\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==========\r\nMichael Jackson died on August 13, 2016, at the age of 50. He was diagnosed with multiple health issues, including kidney failure, in 2009, and passed away due to complications from his treatment.\r\n==========\r\nPrompt: 39 tokens, 104.885 tokens-per-sec\r\nGeneration: 53 tokens, 221.708 tokens-per-sec\r\nPeak memory: 0.572 GB\r\n```\n:::\n:::\n\n\n## Fine-tuning with MLX and LoRA\n\nMLX removes the need to write custom Python code to fine-tune, as it provides a set of commands which implement the fine-tuning pipeline without the need for any additional code. The toolset can also use datasets from the Hugging Face model hub - this is exactly what we will do, as we are only illustrating the fine-tuning process with MLX. In most cases you will want to use your own dataset.\n\n::: {.callout-note}\n\nIn other articles we will cover how to perform fine-tuning with your own dataset and using the hugging face `transformers` library [PEFT](https://github.com/huggingface/peft), rather than a prescribed tool such as MLX, [Axolotl](https://github.com/axolotl-ai-cloud/axolotl) or [Unsloth](https://github.com/unslothai/unsloth).\n:::\n\n### Supervised fine-tuning\n\nLet's start with supervised fine-tuning. We will use [`HuggingFaceH4/no_robots`](https://huggingface.co/datasets/HuggingFaceH4/no_robots), a high-quality dataset designed to fine tune LLMs so they follow instructions more preciselly. It contains a set of prompts and the corresponding output text - it is split into `train` and `test` sets, but MLX requires a `validation` set as well, so we will first split the `train` set into `train` and `validation` sets.\n\n::: {.callout-note}\n\nFor the purposes of this exercise, we don't need to worry about the specifics of the dataset, or whether the model improves or not - we are only interested in the process of fine-tuning.\n:::\n\n::: {#02a839b6 .cell execution_count=3}\n``` {.python .cell-code}\nfrom datasets import load_dataset\nimport tqdm as notebook_tqdm\n\ndataset = load_dataset(\"HuggingFaceH4/no_robots\")\n\n# Split train into train and validation\ntrain = dataset[\"train\"].train_test_split(test_size=0.15, seed=42)\ndataset[\"train\"] = train[\"train\"]\ndataset[\"validation\"] = train[\"test\"]\n\nprint(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDatasetDict({\n    train: Dataset({\n        features: ['prompt', 'prompt_id', 'messages', 'category'],\n        num_rows: 8075\n    })\n    test: Dataset({\n        features: ['prompt', 'prompt_id', 'messages', 'category'],\n        num_rows: 500\n    })\n    validation: Dataset({\n        features: ['prompt', 'prompt_id', 'messages', 'category'],\n        num_rows: 1425\n    })\n})\n```\n:::\n:::\n\n\n::: {#529d23a8 .cell execution_count=4}\n``` {.python .cell-code}\nprint(dataset[\"train\"][0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Pretend you are a dog. Send out a text to all your dog friends inviting them to the dog park. Specify that everyone should meet at 2pm today.', 'prompt_id': '4b474f9f59c64e8e32ad346051bb4f8d9b864110c2dda0d481e8f13898dc4511', 'messages': [{'content': 'Pretend you are a dog. Send out a text to all your dog friends inviting them to the dog park. Specify that everyone should meet at 2pm today.', 'role': 'user'}, {'content': \"Hello, my dog friends!\\n\\nIt is such a beautiful day today! Does anyone want to go to the dog park to play catch and chase each other's tails with me? I will be there at 2 pm today. \\n\\nLet me know if you will be there! I'm looking forward to playing with you all!\", 'role': 'assistant'}], 'category': 'Generation'}\n```\n:::\n:::\n\n\nNow let's save the split dataset into a file.\n\n::: {#d347d611 .cell execution_count=5}\n``` {.python .cell-code}\nimport json\nimport os\n\noutput_dir = \"no_robots\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Rename 'validation' to 'valid'\ndataset[\"valid\"] = dataset.pop(\"validation\")\n\nfor split in [\"train\", \"test\", \"valid\"]:\n    dataset[split].to_json(f\"{output_dir}/{split}.jsonl\", lines=True)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"95d07084922e4e4297feefa85a8e1345\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"3409a96b934d4110ad53a3391c8a0bb2\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"95d8daed30824377b0359e6db9d012ce\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n:::\n\n\nAnd finally let us run the fine-tuning process. For the training we will set the number of adapter layers to $8$ (`--num-layers 8`), the batch size to $6$ (`--batch-size 6`), the number of iterations to $1500$ (`--iters 1500`), and we will also checkpoint the model every $100$ iterations (`--grad-checkpoint`). You can pass these parameters directly to the `mlx_lm.train` command, but in our case we want to save them into a configuration `yaml` file.\n\n::: {#9b06fa97 .cell execution_count=6}\n``` {.python .cell-code}\n!cat no_robots-train-params.yaml\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# The path to the local model directory or Hugging Face repo.\r\nmodel: \"/Users/NLeitao/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit\"\r\n\r\n# Whether or not to train (boolean)\r\ntrain: true\r\n\r\n# The fine-tuning method: \"lora\", \"dora\", or \"full\".\r\nfine_tune_type: lora\r\n\r\n# Directory with {train, valid, test}.jsonl files\r\ndata: \"./no_robots\"\r\n\r\n# Number of layers to fine-tune\r\nnum_layers: 16\r\n\r\n# Minibatch size.\r\nbatch_size: 6\r\n\r\n# Iterations to train for.\r\niters: 1000\r\n\r\n# Adam learning rate.\r\nlearning_rate: 1e-4\r\n\r\n# Save/load path for the trained adapter weights.\r\nadapter_path: \"adapter\"\r\n\r\n# Save the model every N iterations.\r\nsave_every: 100\r\n\r\n# Evaluate on the test set after training\r\ntest: true\r\n\r\n# Maximum sequence length.\r\nmax_seq_length: 2048\r\n\r\n# Use gradient checkpointing to reduce memory use.\r\ngrad_checkpoint: true\r\n```\n:::\n:::\n\n\n::: {#4894d246 .cell execution_count=7}\n``` {.python .cell-code}\n!mlx_lm.lora \\\n    --config no_robots-train-params.yaml \\\n    --train \\\n    --test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoading configuration file no_robots-train-params.yaml\r\nLoading pretrained model\r\nTraceback (most recent call last):\r\n  File \"/Volumes/Home/pedroleitao/miniconda3/envs/pedroleitao.nl/bin/mlx_lm.lora\", line 10, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"/Volumes/Home/pedroleitao/miniconda3/envs/pedroleitao.nl/lib/python3.11/site-packages/mlx_lm/lora.py\", line 310, in main\r\n    run(types.SimpleNamespace(**args))\r\n  File \"/Volumes/Home/pedroleitao/miniconda3/envs/pedroleitao.nl/lib/python3.11/site-packages/mlx_lm/lora.py\", line 270, in run\r\n    model, tokenizer = load(args.model)\r\n                       ^^^^^^^^^^^^^^^^\r\n  File \"/Volumes/Home/pedroleitao/miniconda3/envs/pedroleitao.nl/lib/python3.11/site-packages/mlx_lm/utils.py\", line 782, in load\r\n    model_path = get_model_path(path_or_hf_repo)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Volumes/Home/pedroleitao/miniconda3/envs/pedroleitao.nl/lib/python3.11/site-packages/mlx_lm/utils.py\", line 200, in get_model_path\r\n    raise ModelNotFoundError(\r\nmlx_lm.utils.ModelNotFoundError: Model not found for path or HF repo: /Users/NLeitao/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit.\r\nPlease make sure you specified the local path or Hugging Face repo id correctly.\r\nIf you are trying to access a private or gated Hugging Face repo, make sure you are authenticated:\r\nhttps://huggingface.co/docs/huggingface_hub/en/guides/cli#huggingface-cli-login\r\n```\n:::\n:::\n\n\nBatch size is a big contributor to memory usage, so you may need to adjust it depending on your hardware.\n\n::: {.callout-note}\n## About Gradient Checkpointing\n\n[Gradient checkpointing](https://github.com/cybertronai/gradient-checkpointing) is a method that trades off extra computation for lower memory usage during deep learning training. Instead of storing all intermediate outputs needed for backpropagation, the network only checkpoints certain “key” layers. When gradients need to be computed, the forward pass for the missing parts is recomputed on the fly.\n\nBy doing this, the total memory consumption can be drastically reduced—especially for very large models—because you’re not hanging onto every intermediate result. The tradeoff is that you’ll pay with some extra compute time for re-running parts of the forward pass.\n:::\n\nWe just fine-tuned the model, and we can now see the adapter matrices in the `adapter` directory!\n\n::: {#0ad581af .cell execution_count=8}\n``` {.python .cell-code}\n!ls -lh adapter\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntotal 8504\r\n-rw-r--r--@ 1 pedroleitao  staff   1.4M Mar  2 16:06 0000100_adapters.safetensors\r\n-rw-r--r--@ 1 pedroleitao  staff   1.4M Mar  2 16:06 0000200_adapters.safetensors\r\n-rw-r--r--@ 1 pedroleitao  staff   761B Mar  2 16:06 adapter_config.json\r\n-rw-r--r--@ 1 pedroleitao  staff   1.4M Mar  2 16:06 adapters.safetensors\r\n```\n:::\n:::\n\n\nBefore we can use the fine-tuned model, we need to merge (or \"fuse\") the adapter matrices from the fine-tuning training back into the original model. This can be done with the `mlx_lm.fuse` command.\n\n::: {#86def030 .cell execution_count=9}\n``` {.python .cell-code}\n!mlx_lm.fuse \\\n    --model $HOME/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit \\\n    --adapter-path ./adapter \\\n    --save-path $HOME/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit-tuned\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoading pretrained model\r\n```\n:::\n:::\n\n\nAnd finally we can generate text using the fine-tuned model as before.\n\n::: {#1e285ffa .cell execution_count=10}\n``` {.python .cell-code}\n!mlx_lm.generate \\\n    --model $HOME/.lmstudio/models/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-8bit-tuned \\\n    --prompt 'When did Michael Jackson die? Stick to facts.' \\\n    --max-tokens 256\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==========\r\nMichael Jackson died on January 15, 2016.\r\n==========\r\nPrompt: 39 tokens, 1051.475 tokens-per-sec\r\nGeneration: 16 tokens, 256.512 tokens-per-sec\r\nPeak memory: 0.573 GB\r\n```\n:::\n:::\n\n\nWe have just fine-tuned a pre-trained language model using the MLX framework! Note how previously instructing the model to \"stick to facts\" did not result in the desired output (albeight clearly the date is wrong), but after fine-tuning the model on the `no_robots` dataset, the model now generates text that is more in line with the instruction.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"0251b1fd6c234d1aa6275d91281f6800\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_1374ddc3216048a8b63a72ce1e547d26\",\"max\":1,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_f27fc321ddd24f93ad87a5d65e1024ce\",\"tabbable\":null,\"tooltip\":null,\"value\":1}},\"0707a092feb74836915f7847fb15e88d\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_97085f8437a7462481ad3d596c3ba825\",\"max\":9,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_3da0ebc5fb514a1684a46e5155b38237\",\"tabbable\":null,\"tooltip\":null,\"value\":9}},\"0aefd6b9f8654852983bb76a584f1121\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"1374ddc3216048a8b63a72ce1e547d26\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"18579f646a824f0dbe98f8770e9983c1\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"189d6021ea814274860022bfb19151b1\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"2c00a182ab2640b3a7d00868978a3367\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_b2ec23319a24430fb160f59c1b285a48\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_0aefd6b9f8654852983bb76a584f1121\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 9/9 [00:00&lt;00:00, 19.20ba/s]\"}},\"3409a96b934d4110ad53a3391c8a0bb2\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_a2dcca43f1c04d08abdcd4bdbbb4d846\",\"IPY_MODEL_0251b1fd6c234d1aa6275d91281f6800\",\"IPY_MODEL_d593425aa5fa4e0985a87a08c10e2abc\"],\"layout\":\"IPY_MODEL_b1c39b12e35c43b7af7238e7c271ea6c\",\"tabbable\":null,\"tooltip\":null}},\"38369537fe4c470a8cd85d0d4237a828\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"3da0ebc5fb514a1684a46e5155b38237\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"555f51f47acf49a4ac7d824521f6ae77\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_18579f646a824f0dbe98f8770e9983c1\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_c585fb7fcb554408a197b569937ded84\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 2/2 [00:00&lt;00:00, 98.40ba/s]\"}},\"5bbcfccb80e945a38e7e64dd2ba4dfd8\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_c96d691454b74ff5adf1936607198220\",\"max\":2,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_d71f8dc5213d42b99064b71559995ae4\",\"tabbable\":null,\"tooltip\":null,\"value\":2}},\"5fc24973d4c1445483d517be2c95b81f\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"71127552db4b435eb8bef74afd144cf2\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"95d07084922e4e4297feefa85a8e1345\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_be5431d4dd234573844f4ccb67601b6a\",\"IPY_MODEL_0707a092feb74836915f7847fb15e88d\",\"IPY_MODEL_2c00a182ab2640b3a7d00868978a3367\"],\"layout\":\"IPY_MODEL_bcb45104f12f480ea4794009b10e27ce\",\"tabbable\":null,\"tooltip\":null}},\"95d8daed30824377b0359e6db9d012ce\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_efb96bb4049741e9a3f01ef8a0e6c6e0\",\"IPY_MODEL_5bbcfccb80e945a38e7e64dd2ba4dfd8\",\"IPY_MODEL_555f51f47acf49a4ac7d824521f6ae77\"],\"layout\":\"IPY_MODEL_e7d80a15b8484ef88d6de22db2be3188\",\"tabbable\":null,\"tooltip\":null}},\"97085f8437a7462481ad3d596c3ba825\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"a2dcca43f1c04d08abdcd4bdbbb4d846\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_d01d9d18f29e4b6384f63717f631d495\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_189d6021ea814274860022bfb19151b1\",\"tabbable\":null,\"tooltip\":null,\"value\":\"Creating json from Arrow format: 100%\"}},\"b1c39b12e35c43b7af7238e7c271ea6c\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"b2ec23319a24430fb160f59c1b285a48\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"bcb45104f12f480ea4794009b10e27ce\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"be5431d4dd234573844f4ccb67601b6a\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_dc84b7faa74045c8bbd8c3dc516c7ce9\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_71127552db4b435eb8bef74afd144cf2\",\"tabbable\":null,\"tooltip\":null,\"value\":\"Creating json from Arrow format: 100%\"}},\"c585fb7fcb554408a197b569937ded84\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"c96d691454b74ff5adf1936607198220\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"d01d9d18f29e4b6384f63717f631d495\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"d593425aa5fa4e0985a87a08c10e2abc\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_dbb974b83630419787060d296f387e9b\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_5fc24973d4c1445483d517be2c95b81f\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 1/1 [00:00&lt;00:00, 109.35ba/s]\"}},\"d71f8dc5213d42b99064b71559995ae4\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"dbb974b83630419787060d296f387e9b\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"dc84b7faa74045c8bbd8c3dc516c7ce9\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"e7d80a15b8484ef88d6de22db2be3188\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"efb96bb4049741e9a3f01ef8a0e6c6e0\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_38369537fe4c470a8cd85d0d4237a828\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_faccbc7a7b3f4aedb8e0e2ce73a9d54d\",\"tabbable\":null,\"tooltip\":null,\"value\":\"Creating json from Arrow format: 100%\"}},\"f27fc321ddd24f93ad87a5d65e1024ce\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"faccbc7a7b3f4aedb8e0e2ce73a9d54d\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}