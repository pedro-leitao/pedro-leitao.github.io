<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Pedro Leitão</title>
<link>https://pedroleitao.nl/experiments.html</link>
<atom:link href="https://pedroleitao.nl/experiments.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://pedroleitao.nl/_static/logo.png</url>
<title>Pedro Leitão</title>
<link>https://pedroleitao.nl/experiments.html</link>
</image>
<generator>quarto-1.7.23</generator>
<lastBuildDate>Fri, 25 Apr 2025 23:00:00 GMT</lastBuildDate>
<item>
  <title>Dynamic Inventory Management with Reinforcement Learning</title>
  <link>https://pedroleitao.nl/posts/experiments/rl-inventory-optimisation/</link>
  <description><![CDATA[ Businesses struggle to balance inventory: too much stock ties up cash, too little loses sales. Inventory optimisation is a whole field of study, which has a well understood impact of the potential profitability of any business which sells physical goods - the median company <a href="https://www.scmr.com/article/inventory_optimization_show_me_the_money">spends 1% of revenue carrying inventory</a>. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <category>Reinforcement Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/rl-inventory-optimisation/</guid>
  <pubDate>Fri, 25 Apr 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Deblurring, a Classic Machine Learning Problem</title>
  <link>https://pedroleitao.nl/posts/experiments/blade-runner-enhance/</link>
  <description><![CDATA[ train a variational autoencoder to deblur images ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/blade-runner-enhance/</guid>
  <pubDate>Thu, 20 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Mondrianiser: Image Inpainting with VAEs</title>
  <link>https://pedroleitao.nl/posts/experiments/mondrianiser/</link>
  <description><![CDATA[ an example of generative models using a variational autoencoder ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <category>Deep Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/mondrianiser/</guid>
  <pubDate>Mon, 17 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Adam’s Apple</title>
  <link>https://pedroleitao.nl/posts/experiments/adam-optimisation/</link>
  <description><![CDATA[ A key component of training deep learning models is the choice of optimisation algorithm. There are several approaches, ranging from <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">:link simple stochastic gradient descent</a> (SGD) to more advanced methods like Adam. In this experiment, we’ll try to give an intuitive understanding of what optimisation means in the context of machine learning, briefly discussing the Adam algorithm. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <category>Deep Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/adam-optimisation/</guid>
  <pubDate>Fri, 14 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Maps and More Maps</title>
  <link>https://pedroleitao.nl/posts/experiments/maps-and-maps/</link>
  <description><![CDATA[ Recently I was trying to figure out sun exposure for a specific location, except I was a couple of thousand kilometers away, and needed to get a sense of the sun’s path relative to a rooftop. There are quite a few tools available online (like <a href="https://suncalc.org">SunCalc</a>), and some mobile apps which pretty much can do the job. But, I really wanted to find out if I could do it myself from first principles. ]]></description>
  <category>Experiments</category>
  <category>Software Engineering</category>
  <guid>https://pedroleitao.nl/posts/experiments/maps-and-maps/</guid>
  <pubDate>Mon, 10 Mar 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How GPU’s work, an explainer using the Mandelbrot set</title>
  <link>https://pedroleitao.nl/posts/experiments/parallel-mandelbrot/</link>
  <description><![CDATA[ Every day pretty much all of us either uses or hears about the mythical GPU, the Graphics Processing Unit. It’s the thing that makes your games, video renders, and your machine learning models train faster. But how does it achieve that? What makes it different from a CPU? ]]></description>
  <category>Experiments</category>
  <category>GPU</category>
  <guid>https://pedroleitao.nl/posts/experiments/parallel-mandelbrot/</guid>
  <pubDate>Sun, 09 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reinforcement Learning - a Primer using Connect Four</title>
  <link>https://pedroleitao.nl/posts/experiments/connect-four-rl/</link>
  <description><![CDATA[ One of the mainstay algorithms in machine learning is reinforcement learning (or <em>RL</em> for short). RL is an approach to machine learning that is used to teach an agent how to make decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. It learns by interacting with the environment and receiving feedback in the form of rewards or penalties. It then uses this feedback to learn the best strategy for achieving its goal. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <category>Reinforcement Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/connect-four-rl/</guid>
  <pubDate>Sun, 09 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Regularisation in Machine Learning</title>
  <link>https://pedroleitao.nl/posts/experiments/regularisation/</link>
  <description><![CDATA[ Regularisation is a technique designed to prevent models from overfitting. In other words, it helps your model generalise better to unseen data by discouraging it from fitting too closely to the quirks and noise present in your training set. This is typically achieved by adding a penalty term to the model’s cost function, nudging the learning process toward simpler, more robust solutions. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/regularisation/</guid>
  <pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A Classical Machine Learning Problem: Predicting Customer Churn</title>
  <link>https://pedroleitao.nl/posts/experiments/customer-churn/</link>
  <description><![CDATA[ Customer churn, where customers stop using a company’s services, is a major concern for businesses as it directly impacts revenue. Traditionally, companies tackled this issue by manually analyzing past data and relying on the intuition of marketing and sales teams. They used methods like customer surveys, simple statistical analysis, and basic segmentation based on purchase history and customer interactions. These approaches provided some insights but were often reactive and lacked precision. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <guid>https://pedroleitao.nl/posts/experiments/customer-churn/</guid>
  <pubDate>Mon, 08 Jul 2024 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Text Tasks without Neural Networks</title>
  <link>https://pedroleitao.nl/posts/experiments/random-forests-embeddings/</link>
  <description><![CDATA[ Natural language processing (NLP) is often associated with deep learning and neural networks. However, there are efficient methods for text classification that do not rely on neural networks. In this exploration, we will demonstrate a sentiment analysis classification problem using text embeddings combined with traditional machine learning algorithms. ]]></description>
  <category>Experiments</category>
  <category>Machine Learning</category>
  <category>NLP</category>
  <guid>https://pedroleitao.nl/posts/experiments/random-forests-embeddings/</guid>
  <pubDate>Tue, 18 Jun 2024 23:00:00 GMT</pubDate>
</item>
</channel>
</rss>
