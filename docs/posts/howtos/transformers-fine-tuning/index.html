<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-01-05">

<title>Model Fine-tuning with the Hugging Face transformers Library – Pedro Leitão</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../_static/logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-a185852c63625fd9ffbdc57047c9a77e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-9143d267086697ee6a9fbeed7f968a66.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../../site_libs/quarto-contrib/nutshell-1.0.7/nutshell.js"></script>
<script src="../../../site_libs/quarto-contrib/nutshell-1.0.7/nutshell_options.js"></script>
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FQKJNEYQJM"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-FQKJNEYQJM', { 'anonymize_ip': true});
</script>
<meta name="mermaid-theme" content="default">
<script src="../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
<script data-collect-dnt="true" async="" src="https://scripts.simpleanalyticscdn.com/latest.js"></script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Model Fine-tuning with the Hugging Face transformers Library – Pedro Leitão">
<meta property="og:description" content="the basics of traditional fine-tuning">
<meta property="og:image" content="https://pedroleitao.nl/posts/howtos/transformers-fine-tuning/index_files/figure-html/cell-16-output-1.png">
<meta property="og:site_name" content="Pedro Leitão">
<meta property="og:image:height" content="566">
<meta property="og:image:width" content="758">
<meta name="twitter:title" content="Model Fine-tuning with the Hugging Face transformers Library – Pedro Leitão">
<meta name="twitter:description" content="the basics of traditional fine-tuning">
<meta name="twitter:image" content="https://pedroleitao.nl/posts/howtos/transformers-fine-tuning/index_files/figure-html/cell-16-output-1.png">
<meta name="twitter:image-height" content="566">
<meta name="twitter:image-width" content="758">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../_static/logo.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Bio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts.html"> 
<span class="menu-text">All posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../experiments.html"> 
<span class="menu-text">Experiments</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../thoughts.html"> 
<span class="menu-text">Thoughts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../howtos.html"> 
<span class="menu-text">Howto’s</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pedro-leitao"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/nunoleitao"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../posts.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Model Fine-tuning with the Hugging Face <code>transformers</code> Library</h1>
            <p class="subtitle lead">the basics of traditional fine-tuning</p>
                                <div class="quarto-categories">
                <div class="quarto-category">HowTo</div>
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Language Models</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 5, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#producing-a-training-dataset" id="toc-producing-a-training-dataset" class="nav-link active" data-scroll-target="#producing-a-training-dataset">Producing a training dataset</a></li>
  <li><a href="#loading-the-model" id="toc-loading-the-model" class="nav-link" data-scroll-target="#loading-the-model">Loading the model</a></li>
  <li><a href="#configuring-lora" id="toc-configuring-lora" class="nav-link" data-scroll-target="#configuring-lora">Configuring LoRA</a></li>
  <li><a href="#configuring-the-trainer" id="toc-configuring-the-trainer" class="nav-link" data-scroll-target="#configuring-the-trainer">Configuring the trainer</a></li>
  <li><a href="#setting-up-the-trainer" id="toc-setting-up-the-trainer" class="nav-link" data-scroll-target="#setting-up-the-trainer">Setting up the trainer</a></li>
  <li><a href="#evaluating-the-training" id="toc-evaluating-the-training" class="nav-link" data-scroll-target="#evaluating-the-training">Evaluating the training</a></li>
  <li><a href="#merging-adaptations-and-saving-the-model" id="toc-merging-adaptations-and-saving-the-model" class="nav-link" data-scroll-target="#merging-adaptations-and-saving-the-model">Merging adaptations and saving the model</a></li>
  <li><a href="#testing-the-model" id="toc-testing-the-model" class="nav-link" data-scroll-target="#testing-the-model">Testing the model</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Previously, we learned <a href="../../../howtos/fine-tuning/mlx/">how to use Apple’s MLX framework to fine-tune a language model</a>. This is an Apple specific framework and is not available to everyone. Here we will learn how to fine-tune a language model using the Hugging Face <a href="https://huggingface.co/docs/transformers/en/index"><code>transformers</code></a> library. This library is widely used and supports a variety of models on different platforms and hardware.</p>
<p>It is also the basis for many other tools, such as <a href="https://github.com/axolotl-ai-cloud/axolotl"><code>Axolotl</code></a>, <a href="https://github.com/oumi-ai/oumi?tab=readme-ov-file"><code>oumi</code></a> and <a href="https://unsloth.ai"><code>unsloth</code></a> which ease and automate much of the fine-tuning pipeline. Even if you rely on these tools for your work, it is still important to understand the underlying <code>transformers</code> library and how to use it directly, even if only to get an intuition for how these tools work.</p>
<p>As we did before when we fine-tuned a model with MLX, we will use the LoRA approach as opposed to fine-tuning the entire model.</p>
<div id="30f28f0c" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="30f28f0c"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="30f28f0c-1"><a href="#30f28f0c-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="30f28f0c-2"><a href="#30f28f0c-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="30f28f0c-3"><a href="#30f28f0c-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="30f28f0c-4"><a href="#30f28f0c-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="30f28f0c-5"><a href="#30f28f0c-5" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="30f28f0c-6"><a href="#30f28f0c-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="30f28f0c-7"><a href="#30f28f0c-7" aria-hidden="true" tabindex="-1"></a>random.seed(SEED)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="a95e87d3" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="a95e87d3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="a95e87d3-1"><a href="#a95e87d3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> set_seed</span>
<span id="a95e87d3-2"><a href="#a95e87d3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="a95e87d3-3"><a href="#a95e87d3-3" aria-hidden="true" tabindex="-1"></a>set_seed(SEED)  <span class="co"># Covers Transformers, Tokenizers, and Datasets</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="producing-a-training-dataset" class="level2">
<h2 class="anchored" data-anchor-id="producing-a-training-dataset">Producing a training dataset</h2>
<p>In this example, we will be fine-tuning a tiny <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct"><code>Qwen2.5-0.5B-Instruct</code></a> model to perform very basic arithmetic operations. We will generate a dataset of arithmetic problems and their solutions to train the model. Qwen2.5 is an open-source model from Alibaba, which offers a collection of language models trained on a variety of tasks.</p>
<p>The overall fine-tuning workflow follows a straightforward set of steps.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    A[Pre-trained Language Model] --&gt; B([Dataset Preparation])
    B --&gt; C[Data Preprocessing]
    C --&gt; D((Fine-tune Model))
    D --&gt; E[Evaluate Model]
    E --&gt; F{Satisfactory?}
    F -- No - Adjust Dataset --&gt; B
    F -- No - Adjust Hyperparameters --&gt; D
    F -- Yes --&gt; G[Deploy Model]

    style D fill:#ffcccc,stroke:#ff0000,stroke-dasharray:5,5
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Let us start with a function which generates the necessary dataset in the appropriate chat format for the <code>transformers</code> library.</p>
<div id="a909a234" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="a909a234"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="a909a234-1"><a href="#a909a234-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="a909a234-2"><a href="#a909a234-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="a909a234-3"><a href="#a909a234-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-4"><a href="#a909a234-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-5"><a href="#a909a234-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_arithmetic_dataset(n_samples: <span class="bu">int</span>) <span class="op">-&gt;</span> Dataset:</span>
<span id="a909a234-6"><a href="#a909a234-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="a909a234-7"><a href="#a909a234-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Generates arithmetic problems using numbers 0-100 in the specified message format</span></span>
<span id="a909a234-8"><a href="#a909a234-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="a909a234-9"><a href="#a909a234-9" aria-hidden="true" tabindex="-1"></a>    operations <span class="op">=</span> [<span class="st">"+"</span>, <span class="st">"-"</span>, <span class="st">"*"</span>]</span>
<span id="a909a234-10"><a href="#a909a234-10" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="a909a234-11"><a href="#a909a234-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-12"><a href="#a909a234-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="a909a234-13"><a href="#a909a234-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate arithmetic problem with 0-100 numbers</span></span>
<span id="a909a234-14"><a href="#a909a234-14" aria-hidden="true" tabindex="-1"></a>        op <span class="op">=</span> random.choice(operations)</span>
<span id="a909a234-15"><a href="#a909a234-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="dv">200</span>)</span>
<span id="a909a234-16"><a href="#a909a234-16" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="dv">200</span>)</span>
<span id="a909a234-17"><a href="#a909a234-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-18"><a href="#a909a234-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate result with clean formatting</span></span>
<span id="a909a234-19"><a href="#a909a234-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> op <span class="op">==</span> <span class="st">"+"</span>:</span>
<span id="a909a234-20"><a href="#a909a234-20" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> x <span class="op">+</span> y</span>
<span id="a909a234-21"><a href="#a909a234-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> op <span class="op">==</span> <span class="st">"-"</span>:</span>
<span id="a909a234-22"><a href="#a909a234-22" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> random.randint(<span class="dv">0</span>, x)</span>
<span id="a909a234-23"><a href="#a909a234-23" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> x <span class="op">-</span> y</span>
<span id="a909a234-24"><a href="#a909a234-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> op <span class="op">==</span> <span class="st">"*"</span>:</span>
<span id="a909a234-25"><a href="#a909a234-25" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> x <span class="op">*</span> y</span>
<span id="a909a234-26"><a href="#a909a234-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-27"><a href="#a909a234-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create problem string without negative formatting</span></span>
<span id="a909a234-28"><a href="#a909a234-28" aria-hidden="true" tabindex="-1"></a>        problem <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>x<span class="sc">}{</span>op<span class="sc">}{</span>y<span class="sc">}</span><span class="ss">"</span></span>
<span id="a909a234-29"><a href="#a909a234-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-30"><a href="#a909a234-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Format final equation</span></span>
<span id="a909a234-31"><a href="#a909a234-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># full_equation = f"x is {result}"</span></span>
<span id="a909a234-32"><a href="#a909a234-32" aria-hidden="true" tabindex="-1"></a>        full_equation <span class="op">=</span> <span class="ss">f"x is </span><span class="sc">{</span>result<span class="sc">}</span><span class="ss">"</span></span>
<span id="a909a234-33"><a href="#a909a234-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-34"><a href="#a909a234-34" aria-hidden="true" tabindex="-1"></a>        variations <span class="op">=</span> [</span>
<span id="a909a234-35"><a href="#a909a234-35" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Prepositional Variations</span></span>
<span id="a909a234-36"><a href="#a909a234-36" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Assuming x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-37"><a href="#a909a234-37" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Provided x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-38"><a href="#a909a234-38" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"With x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> given, solve for x."</span>,</span>
<span id="a909a234-39"><a href="#a909a234-39" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Under the condition x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-40"><a href="#a909a234-40" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Using x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-41"><a href="#a909a234-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Conditional Clause Variations</span></span>
<span id="a909a234-42"><a href="#a909a234-42" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"If x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> is provided, solve for x."</span>,</span>
<span id="a909a234-43"><a href="#a909a234-43" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"When x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> is given, solve for x."</span>,</span>
<span id="a909a234-44"><a href="#a909a234-44" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"In the case where x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-45"><a href="#a909a234-45" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"For the equation x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-46"><a href="#a909a234-46" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Given that x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-47"><a href="#a909a234-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Participial Phrase Variations</span></span>
<span id="a909a234-48"><a href="#a909a234-48" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Starting from x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-49"><a href="#a909a234-49" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Taking x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> into account, solve for x."</span>,</span>
<span id="a909a234-50"><a href="#a909a234-50" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Having x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-51"><a href="#a909a234-51" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Basing your work on x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-52"><a href="#a909a234-52" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Considering x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-53"><a href="#a909a234-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Imperative Variations</span></span>
<span id="a909a234-54"><a href="#a909a234-54" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Solve for x, given x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">."</span>,</span>
<span id="a909a234-55"><a href="#a909a234-55" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Use x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> to solve for x."</span>,</span>
<span id="a909a234-56"><a href="#a909a234-56" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Work with x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> and solve for x."</span>,</span>
<span id="a909a234-57"><a href="#a909a234-57" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Begin with x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, then solve for x."</span>,</span>
<span id="a909a234-58"><a href="#a909a234-58" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Take x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss"> and solve for x."</span>,</span>
<span id="a909a234-59"><a href="#a909a234-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Expanded/Explicit Variations</span></span>
<span id="a909a234-60"><a href="#a909a234-60" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Given the value x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, determine the solution for x."</span>,</span>
<span id="a909a234-61"><a href="#a909a234-61" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Using the premise that x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, find the value of x."</span>,</span>
<span id="a909a234-62"><a href="#a909a234-62" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Under the assumption that x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, compute x."</span>,</span>
<span id="a909a234-63"><a href="#a909a234-63" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"If we define x as </span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-64"><a href="#a909a234-64" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Based on the equation x=</span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">, solve for x."</span>,</span>
<span id="a909a234-65"><a href="#a909a234-65" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="a909a234-66"><a href="#a909a234-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-67"><a href="#a909a234-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create conversation structure</span></span>
<span id="a909a234-68"><a href="#a909a234-68" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> random.choice(variations)</span>
<span id="a909a234-69"><a href="#a909a234-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-70"><a href="#a909a234-70" aria-hidden="true" tabindex="-1"></a>        samples.append(</span>
<span id="a909a234-71"><a href="#a909a234-71" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="a909a234-72"><a href="#a909a234-72" aria-hidden="true" tabindex="-1"></a>                <span class="st">"messages"</span>: [</span>
<span id="a909a234-73"><a href="#a909a234-73" aria-hidden="true" tabindex="-1"></a>                    {<span class="st">"content"</span>: prompt, <span class="st">"role"</span>: <span class="st">"user"</span>},</span>
<span id="a909a234-74"><a href="#a909a234-74" aria-hidden="true" tabindex="-1"></a>                    {<span class="st">"content"</span>: full_equation, <span class="st">"role"</span>: <span class="st">"assistant"</span>},</span>
<span id="a909a234-75"><a href="#a909a234-75" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="a909a234-76"><a href="#a909a234-76" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="a909a234-77"><a href="#a909a234-77" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="a909a234-78"><a href="#a909a234-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="a909a234-79"><a href="#a909a234-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Dataset.from_list(samples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="84c8dd42" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="84c8dd42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="84c8dd42-1"><a href="#84c8dd42-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> generate_arithmetic_dataset(<span class="dv">20000</span>)</span>
<span id="84c8dd42-2"><a href="#84c8dd42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="84c8dd42-3"><a href="#84c8dd42-3" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Dataset({
    features: ['messages'],
    num_rows: 20000
})</code></pre>
</div>
</div>
<p>With the dataset generated, let us look at a few examples to understand what we will be training the model on.</p>
<div id="2562f0c8" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="2562f0c8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="2562f0c8-1"><a href="#2562f0c8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first few dataset entries</span></span>
<span id="2562f0c8-2"><a href="#2562f0c8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="2562f0c8-3"><a href="#2562f0c8-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(dataset[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>{'messages': [{'content': 'If we define x as 28*6, solve for x.', 'role': 'user'}, {'content': 'x is 168', 'role': 'assistant'}]}
{'messages': [{'content': 'If we define x as 62-8, solve for x.', 'role': 'user'}, {'content': 'x is 54', 'role': 'assistant'}]}
{'messages': [{'content': 'Work with x=173+189 and solve for x.', 'role': 'user'}, {'content': 'x is 362', 'role': 'assistant'}]}
{'messages': [{'content': 'Provided x=151+108, solve for x.', 'role': 'user'}, {'content': 'x is 259', 'role': 'assistant'}]}
{'messages': [{'content': 'In the case where x=23+55, solve for x.', 'role': 'user'}, {'content': 'x is 78', 'role': 'assistant'}]}
{'messages': [{'content': 'Work with x=154*6 and solve for x.', 'role': 'user'}, {'content': 'x is 924', 'role': 'assistant'}]}
{'messages': [{'content': 'Under the assumption that x=183+166, compute x.', 'role': 'user'}, {'content': 'x is 349', 'role': 'assistant'}]}
{'messages': [{'content': 'Considering x=107*56, solve for x.', 'role': 'user'}, {'content': 'x is 5992', 'role': 'assistant'}]}
{'messages': [{'content': 'Based on the equation x=71*1, solve for x.', 'role': 'user'}, {'content': 'x is 71', 'role': 'assistant'}]}
{'messages': [{'content': 'Starting from x=178+108, solve for x.', 'role': 'user'}, {'content': 'x is 286', 'role': 'assistant'}]}</code></pre>
</div>
</div>
<p>We are providing the model with basic arithmetic problems. Think of this as a simple calculator for 7 year olds, where we want the model to recognize a pattern of problems, and to be able to return back a consistent output which doesn’t vary in form for a variety of inputs. The format you see above is called the <code>chat</code> format, which is a simple JSON format that the <code>transformers</code> library uses for training. It is also used by OpenAI in their GPT API.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise suggestion
</div>
</div>
<div class="callout-body-container callout-body">
<p>As an exercise, maybe you want to try training a similar model to interpret a similar problem expressed in JSON format, and to return the answer in structured JSON.</p>
</div>
</div>
</section>
<section id="loading-the-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-model">Loading the model</h2>
<p>With a dataset ready, we can now load the model we want to fine-tune. We will use the <code>Qwen2.5-0.5B-Instruct</code> model from the Hugging Face model hub. This is a tiny model with half a billion parameters, and is a good starting point for fine-tuning experiments as it requires less computational resources.</p>
<div id="d565b73a" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="d565b73a"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="d565b73a-1"><a href="#d565b73a-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="d565b73a-2"><a href="#d565b73a-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="d565b73a-3"><a href="#d565b73a-3" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"Qwen/Qwen2.5-0.5B-Instruct"</span></span>
<span id="d565b73a-4"><a href="#d565b73a-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="d565b73a-5"><a href="#d565b73a-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span>
<span id="d565b73a-6"><a href="#d565b73a-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="d565b73a-7"><a href="#d565b73a-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="d565b73a-8"><a href="#d565b73a-8" aria-hidden="true" tabindex="-1"></a>model.config.use_cache <span class="op">=</span> <span class="va">False</span>  <span class="co"># important with gradient checkpointing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For reference, the input to the model will be tokenized using the model’s tokenizer, and the output will be a sequence of tokens, in a format called <code>ChatML</code>, which includes special tokens which are meaningful the pre-trained model.</p>
<div id="81a2371a" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="81a2371a"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="81a2371a-1"><a href="#81a2371a-1" aria-hidden="true" tabindex="-1"></a>tokenizer.apply_chat_template(dataset[<span class="dv">0</span>][<span class="st">"messages"</span>], tokenize<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>'&lt;|im_start|&gt;system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nIf we define x as 28*6, solve for x.&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nx is 168&lt;|im_end|&gt;\n'</code></pre>
</div>
</div>
<p>Notice the <code>&lt;|im_start"&gt;</code> and <code>&lt;|im_end|&gt;</code> tokens. These are special tokens that the model uses to understand the start and end of the input sequence for each role (the prompter, and the assistant which represents the expected output from the model). The model will be trained to generate the output sequence between these tokens.</p>
<p>Before we start training, let’s split the dataset into training and validation sets.</p>
<div id="ae64740d" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="ae64740d"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="ae64740d-1"><a href="#ae64740d-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="ae64740d-2"><a href="#ae64740d-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="ae64740d-3"><a href="#ae64740d-3" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['messages'],
        num_rows: 18000
    })
    test: Dataset({
        features: ['messages'],
        num_rows: 2000
    })
})</code></pre>
</div>
</div>
<p>Let’s also look at the architecture of the model we are fine-tuning. It is important to have a sense of the model’s layers as this will directly impact how LoRA will be applied.</p>
<div id="c343e386" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="c343e386"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="c343e386-1"><a href="#c343e386-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span>
<span id="c343e386-2"><a href="#c343e386-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="c343e386-3"><a href="#c343e386-3" aria-hidden="true" tabindex="-1"></a>pprint(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Qwen2ForCausalLM(
  (model): Qwen2Model(
    (embed_tokens): Embedding(151936, 896)
    (layers): ModuleList(
      (0-23): 24 x Qwen2DecoderLayer(
        (self_attn): Qwen2Attention(
          (q_proj): Linear(in_features=896, out_features=896, bias=True)
          (k_proj): Linear(in_features=896, out_features=128, bias=True)
          (v_proj): Linear(in_features=896, out_features=128, bias=True)
          (o_proj): Linear(in_features=896, out_features=896, bias=False)
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)
          (up_proj): Linear(in_features=896, out_features=4864, bias=False)
          (down_proj): Linear(in_features=4864, out_features=896, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((896,), eps=1e-06)
    (rotary_emb): Qwen2RotaryEmbedding()
  )
  (lm_head): Linear(in_features=896, out_features=151936, bias=False)
)</code></pre>
</div>
</div>
<p>Imagine the entire model as <code>Qwen2ForCausalLM</code>. At its core, we have <code>Qwen2Model</code>, which contains several parts. First, there’s an embedding layer (<code>embed_tokens</code>) that transforms tokens from a large vocabulary into 896-dimensional vectors. These vectors are then processed by 24 identical layers, which we can denote as L₀ to L₂₃ (each being a <code>Qwen2DecoderLayer</code>).</p>
<p>Inside each layer Lᵢ, the process starts with self-attention (<code>self_attn</code>), where the input is projected into three spaces: queries (via <code>q_proj</code>), keys (via <code>k_proj</code>), and values (via <code>v_proj</code>). These projections are linear transformations that help the model focus on relevant parts of the input. After the attention calculations, the results are recombined through <code>o_proj</code>, another linear transformation that brings the data back to the original 896 dimensions.</p>
<p>Following attention, each layer includes a feed-forward network (<code>mlp</code>). This part consists of a couple of linear layers: <code>gate_proj</code> and <code>up_proj</code> expand the data to a larger dimension (4864), then <code>down_proj</code> compresses it back to 896. An activation function, <code>SiLU</code>, introduces non-linearity, allowing the model to capture more complex patterns.</p>
<p>Also within each layer Lᵢ, there are two normalization modules: <code>input_layernorm</code> is applied before the self-attention to stabilize the inputs, and <code>post_attention_layernorm</code> is applied after self-attention to help keep the network stable as the data moves through the layer.</p>
<p>After processing through all 24 layers, the model applies a final normalization <code>norm</code> to the output. Alongside these, there’s a rotary embedding module, <code>rotary_emb</code>, which helps encode positional information into the vectors.</p>
<p>Finally, the processed data is fed into <code>lm_head</code>, which is a linear layer that projects the final 896-dimensional representations back to the vocabulary size (151936). This final step allows the model to predict the next token based on the processed context.</p>
<p>LoRA essentially adds small, trainable “patches” to the existing linear layers without modifying the core weights. Imagine each weight matrix, like those in <code>q_proj</code> or in the feed-forward network (<code>gate_proj</code>, <code>up_proj</code>, <code>down_proj</code>), is now accompanied by an extra low-rank update. Instead of changing the full 896×896 matrix directly, LoRA introduces two smaller matrices whose product—when added to the original weight—captures the necessary adjustment during fine-tuning. This means that during training, only these additional matrices are updated, leaving the main model untouched. In our architecture, LoRA can be applied to components like the attention projections and MLP layers, efficiently steering the model to adapt to new tasks with much fewer trainable parameters.</p>
</section>
<section id="configuring-lora" class="level2">
<h2 class="anchored" data-anchor-id="configuring-lora">Configuring LoRA</h2>
<p>Now that we have a sense of the model’s architecture, we can configure LoRA. The setup uses small matrices (<code>rank 16</code>) which are added to specific parts of the model. The number 32 (<code>alpha</code>) controls how much these new matrices affect the original weights – like a volume knob for the adjustments. A small 5% dropout (<code>lora_dropout</code>) is applied to these added components to prevent overfitting.</p>
<p>It targets all linear layers (<code>target_modules</code>) in the model for adaptation (like attention and feed-forward layers) while explicitly keeping the word embedding layer and the final output layer (<code>lm_head</code>) fully trainable. The <code>bias</code> terms in the original model remain frozen. This configuration is specifically designed for causal language modeling tasks like text generation, where the model predicts the next word in a sequence. The approach balances efficiency (only modifying parts of the model) with flexibility (keeping key components like embeddings trainable).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the LoRA rank
</div>
</div>
<div class="callout-body-container callout-body">
<p>When we talk about “rank 16” in LoRA, we’re simplifying how a large language model gets adjusted during fine-tuning. Imagine you have a giant spreadsheet of numbers (the model’s weights) that controls how the model behaves. Updating every single number in that spreadsheet would take a lot of time and energy. Instead, LoRA uses a clever shortcut: it breaks down those updates into two smaller, simpler spreadsheets.</p>
<p>The “rank” (in this case, 16) determines how “detailed” these smaller spreadsheets are. A rank of 16 means we’re capturing the most important 16 patterns or directions in the data needed to tweak the model. Think of it like summarizing a long, complicated book with just 16 key bullet points—enough to get the main ideas without memorizing every word.</p>
<p>By using rank 16, LoRA trains only a tiny fraction of the original parameters, making the process faster and more efficient. The trade-off is that we’re approximating changes rather than updating everything perfectly, but in practice, this works surprisingly well for adapting models to new tasks. The value 16 itself is a balance—small enough to save resources, but large enough to retain useful flexibility for learning.</p>
</div>
</div>
<div id="44ce37b3" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="44ce37b3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="44ce37b3-1"><a href="#44ce37b3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> LoraConfig</span>
<span id="44ce37b3-2"><a href="#44ce37b3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="44ce37b3-3"><a href="#44ce37b3-3" aria-hidden="true" tabindex="-1"></a>lora_config <span class="op">=</span> LoraConfig(</span>
<span id="44ce37b3-4"><a href="#44ce37b3-4" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">16</span>,</span>
<span id="44ce37b3-5"><a href="#44ce37b3-5" aria-hidden="true" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">32</span>,</span>
<span id="44ce37b3-6"><a href="#44ce37b3-6" aria-hidden="true" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="44ce37b3-7"><a href="#44ce37b3-7" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="44ce37b3-8"><a href="#44ce37b3-8" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span><span class="st">"all-linear"</span>,</span>
<span id="44ce37b3-9"><a href="#44ce37b3-9" aria-hidden="true" tabindex="-1"></a>    modules_to_save<span class="op">=</span>[<span class="st">"lm_head"</span>, <span class="st">"embed_token"</span>],</span>
<span id="44ce37b3-10"><a href="#44ce37b3-10" aria-hidden="true" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">"CAUSAL_LM"</span>,</span>
<span id="44ce37b3-11"><a href="#44ce37b3-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="configuring-the-trainer" class="level2">
<h2 class="anchored" data-anchor-id="configuring-the-trainer">Configuring the trainer</h2>
<p>With the model and LoRA configured, we can now set up the trainer. We will use the <a href="https://huggingface.co/docs/trl/en/index"><code>TRL</code></a> library, which provides a number of fine-tuning strategies, including supervised fine-tuning, reinforcement learning, direct preference optimization, and more. In this case, we will use the supervised fine-tuning strategy.</p>
<p>First, we need to configure the training arguments. We will set the number of epochs to 5, the learning rate to 2e-5, and the batch size to 4. Depending on what precisely you are fine-tuning the model for, you will need to adjust these values for best results.</p>
<div id="1b332f78" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="1b332f78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="1b332f78-1"><a href="#1b332f78-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trl <span class="im">import</span> SFTConfig</span>
<span id="1b332f78-2"><a href="#1b332f78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="1b332f78-3"><a href="#1b332f78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># For this to work on Apple Silicon, PYTORCH_ENABLE_MPS_FALLBACK=1 must be set as an environment variable</span></span>
<span id="1b332f78-4"><a href="#1b332f78-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="1b332f78-5"><a href="#1b332f78-5" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> SFTConfig(</span>
<span id="1b332f78-6"><a href="#1b332f78-6" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned"</span>,</span>
<span id="1b332f78-7"><a href="#1b332f78-7" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">"logs"</span>,</span>
<span id="1b332f78-8"><a href="#1b332f78-8" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="1b332f78-9"><a href="#1b332f78-9" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="1b332f78-10"><a href="#1b332f78-10" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="1b332f78-11"><a href="#1b332f78-11" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="1b332f78-12"><a href="#1b332f78-12" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="1b332f78-13"><a href="#1b332f78-13" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">50</span>,</span>
<span id="1b332f78-14"><a href="#1b332f78-14" aria-hidden="true" tabindex="-1"></a>    eval_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="1b332f78-15"><a href="#1b332f78-15" aria-hidden="true" tabindex="-1"></a>    eval_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="1b332f78-16"><a href="#1b332f78-16" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="1b332f78-17"><a href="#1b332f78-17" aria-hidden="true" tabindex="-1"></a>    save_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="1b332f78-18"><a href="#1b332f78-18" aria-hidden="true" tabindex="-1"></a>    max_seq_length<span class="op">=</span><span class="dv">128</span>,</span>
<span id="1b332f78-19"><a href="#1b332f78-19" aria-hidden="true" tabindex="-1"></a>    gradient_checkpointing<span class="op">=</span><span class="va">True</span>,</span>
<span id="1b332f78-20"><a href="#1b332f78-20" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="1b332f78-21"><a href="#1b332f78-21" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="1b332f78-22"><a href="#1b332f78-22" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,  <span class="co"># Necessary for early stopping</span></span>
<span id="1b332f78-23"><a href="#1b332f78-23" aria-hidden="true" tabindex="-1"></a>    metric_for_best_model<span class="op">=</span><span class="st">"eval_loss"</span>,</span>
<span id="1b332f78-24"><a href="#1b332f78-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We are using an evaluation strategy (<code>eval_strategy</code>) of <code>steps</code>, which means that the model will be evaluated every 100 steps. Again, depending on your dataset and model, you will need to adjust this value. Other evaluation strategies include no evaluation, and <code>epoch</code>, which evaluates the model at the end of each epoch. The warmup ratio (<code>warmup_ratio</code>) is set to 0.05, which means that the learning rate will increase linearly for the first 5% of the training steps.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the warmup ratio
</div>
</div>
<div class="callout-body-container callout-body">
<p>At the beginning of training, the learning rate (how aggressively the model updates its weights) starts very low, often near zero. Over a small fraction of the total training steps (determined by the <code>warmup_ratio</code>), the learning rate slowly increases to its maximum value. For example, if your total training is 1000 steps and the warmup_ratio is 0.1, the first 100 steps will gradually “warm up” the learning rate. This helps prevent the model from making erratic, unstable updates early on, when its initial guesses are still random. After the warmup phase, the learning rate typically follows a schedule (like decreasing over time). A common ratio is 0.1 (10% of training steps), but it depends on the task — larger ratios give slower warmups, smaller ones start faster.</p>
</div>
</div>
</section>
<section id="setting-up-the-trainer" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-trainer">Setting up the trainer</h2>
<p>With the training arguments configured, we can now set up the trainer. We will use the <code>SFTTrainer</code> class from the <code>TRL</code> library. This class takes the model, training arguments, and the dataset as input. The trainer will implicitly use the model’s tokenizer to tokenize the input data the way the model expects. We are also configuring an early stopping callback, which will stop training if the model’s performance does not improve after 2 evaluations.</p>
<div id="3090486b" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="3090486b"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="3090486b-1"><a href="#3090486b-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trl <span class="im">import</span> SFTTrainer</span>
<span id="3090486b-2"><a href="#3090486b-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> EarlyStoppingCallback</span>
<span id="3090486b-3"><a href="#3090486b-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="3090486b-4"><a href="#3090486b-4" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SFTTrainer(</span>
<span id="3090486b-5"><a href="#3090486b-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="3090486b-6"><a href="#3090486b-6" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="3090486b-7"><a href="#3090486b-7" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>dataset[<span class="st">"train"</span>],</span>
<span id="3090486b-8"><a href="#3090486b-8" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>dataset[<span class="st">"test"</span>],</span>
<span id="3090486b-9"><a href="#3090486b-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># dataset_text_field="messages",</span></span>
<span id="3090486b-10"><a href="#3090486b-10" aria-hidden="true" tabindex="-1"></a>    peft_config<span class="op">=</span>lora_config,</span>
<span id="3090486b-11"><a href="#3090486b-11" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[</span>
<span id="3090486b-12"><a href="#3090486b-12" aria-hidden="true" tabindex="-1"></a>        EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">2</span>, early_stopping_threshold<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="3090486b-13"><a href="#3090486b-13" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="3090486b-14"><a href="#3090486b-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9d6590ba787a43fb9807929851184813","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"99453fa1e6f54483bb5172aa5d18191e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8b6aefc48c514b5e8b8a830eaa49c01e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c4707b24db3a418a88a39d8fc1d6e207","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"609cec2c9d5f40849fbe5aa7ed9ed681","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2619f777005b4db5a3b364d96891e5c5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3039972e14c3419b96647824bfb8b6ac","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7de507ec958844b4b5353a42f2f98651","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<p>We are now ready to kick off the training process. This will take some time, depending on the size of the model, the dataset, and the hardware you are using. It is a good idea to setup a checkpointing mechanism to save the model’s state at regular intervals, so you can resume training if it is interrupted - we do so with <code>resume_from_checkpoint</code>.</p>
<div id="a4fee266" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="a4fee266"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="a4fee266-1"><a href="#a4fee266-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers.trainer_utils <span class="im">import</span> get_last_checkpoint</span>
<span id="a4fee266-2"><a href="#a4fee266-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="a4fee266-3"><a href="#a4fee266-3" aria-hidden="true" tabindex="-1"></a>last_checkpoint <span class="op">=</span> get_last_checkpoint(training_args.output_dir)</span>
<span id="a4fee266-4"><a href="#a4fee266-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="a4fee266-5"><a href="#a4fee266-5" aria-hidden="true" tabindex="-1"></a>trainer.train(resume_from_checkpoint<span class="op">=</span>last_checkpoint)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="1300" max="5625" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1300/5625 05:02 &lt; 1:50:12, 0.65 it/s, Epoch 1/5]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1200</td>
<td>0.293900</td>
<td>0.300763</td>
</tr>
<tr class="even">
<td>1300</td>
<td>0.295200</td>
<td>0.299928</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>TrainOutput(global_step=1300, training_loss=0.045219946641188405, metrics={'train_runtime': 306.4403, 'train_samples_per_second': 293.695, 'train_steps_per_second': 18.356, 'total_flos': 3436998558928896.0, 'train_loss': 0.045219946641188405})</code></pre>
</div>
</div>
<p>Training stopped after about 700 steps, as the model’s performance did not improve after 2 consecutive evaluations.</p>
</section>
<section id="evaluating-the-training" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-the-training">Evaluating the training</h2>
<p>Once the training is complete, we can evaluate the model on the validation set. We will use the <code>evaluate</code> method of the trainer to do this. The method will return a dictionary with the evaluation metrics. You will mostly be interested in the <code>eval_loss</code> value, which tells you how well the model is performing on the validation set, as well as the <code>perplexity</code> measure.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About perplexity
</div>
</div>
<div class="callout-body-container callout-body">
<p>Perplexity, in the context of training a model like a language model, is a way to measure how “confused” the model is when trying to predict outcomes—like guessing the next word in a sentence. Think of it as a score that tells you how well the model understands the patterns in the data it’s trained on. If perplexity is low, the model is making confident, accurate predictions (like a student getting all answer right). If it’s high, the model is struggling (like a student guessing randomly).</p>
<p>Mathematically, it’s tied to how likely the model thinks the data it sees is. For example, if the model assigns high probabilities to correct answers (e.g., predicting the next word in a sentence), perplexity drops. If it spreads probability thinly across many wrong options, perplexity rises. A value of 20 means the model is, on average, as uncertain as if it had to choose between 20 equally likely options for every prediction.</p>
<p>During training, lowering perplexity on validation data is a key goal. It signals the model is learning meaningful patterns rather than memorizing noise.</p>
</div>
</div>
<div id="3e889791" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="3e889791"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="3e889791-1"><a href="#3e889791-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="3e889791-2"><a href="#3e889791-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="3e889791-3"><a href="#3e889791-3" aria-hidden="true" tabindex="-1"></a>eval_results <span class="op">=</span> trainer.evaluate()</span>
<span id="3e889791-4"><a href="#3e889791-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(eval_results)</span>
<span id="3e889791-5"><a href="#3e889791-5" aria-hidden="true" tabindex="-1"></a>final_loss <span class="op">=</span> eval_results[<span class="st">"eval_loss"</span>]</span>
<span id="3e889791-6"><a href="#3e889791-6" aria-hidden="true" tabindex="-1"></a>final_ppl <span class="op">=</span> math.exp(final_loss)</span>
<span id="3e889791-7"><a href="#3e889791-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Perplexity:"</span>, final_ppl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="250" max="250" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [250/250 00:21]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'eval_loss': 0.2982024550437927, 'eval_runtime': 21.9586, 'eval_samples_per_second': 91.08, 'eval_steps_per_second': 11.385}
Perplexity: 1.3474345551889422</code></pre>
</div>
</div>
<p>Let’s visualize the evaluation loss over the training steps to see how the model performed during training.</p>
<div id="5d3e4166" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="5d3e4166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="5d3e4166-1"><a href="#5d3e4166-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="5d3e4166-2"><a href="#5d3e4166-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-3"><a href="#5d3e4166-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect training history</span></span>
<span id="5d3e4166-4"><a href="#5d3e4166-4" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> trainer.state.log_history</span>
<span id="5d3e4166-5"><a href="#5d3e4166-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-6"><a href="#5d3e4166-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract metrics</span></span>
<span id="5d3e4166-7"><a href="#5d3e4166-7" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> [x[<span class="st">"loss"</span>] <span class="cf">for</span> x <span class="kw">in</span> history <span class="cf">if</span> <span class="st">"loss"</span> <span class="kw">in</span> x]</span>
<span id="5d3e4166-8"><a href="#5d3e4166-8" aria-hidden="true" tabindex="-1"></a>eval_loss <span class="op">=</span> [x[<span class="st">"eval_loss"</span>] <span class="cf">for</span> x <span class="kw">in</span> history <span class="cf">if</span> <span class="st">"eval_loss"</span> <span class="kw">in</span> x]</span>
<span id="5d3e4166-9"><a href="#5d3e4166-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-10"><a href="#5d3e4166-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create steps for x-axis</span></span>
<span id="5d3e4166-11"><a href="#5d3e4166-11" aria-hidden="true" tabindex="-1"></a>train_steps <span class="op">=</span> [x[<span class="st">"step"</span>] <span class="cf">for</span> x <span class="kw">in</span> history <span class="cf">if</span> <span class="st">"loss"</span> <span class="kw">in</span> x]</span>
<span id="5d3e4166-12"><a href="#5d3e4166-12" aria-hidden="true" tabindex="-1"></a>eval_steps <span class="op">=</span> [x[<span class="st">"step"</span>] <span class="cf">for</span> x <span class="kw">in</span> history <span class="cf">if</span> <span class="st">"eval_loss"</span> <span class="kw">in</span> x]</span>
<span id="5d3e4166-13"><a href="#5d3e4166-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-14"><a href="#5d3e4166-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training and evaluation loss</span></span>
<span id="5d3e4166-15"><a href="#5d3e4166-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="5d3e4166-16"><a href="#5d3e4166-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-17"><a href="#5d3e4166-17" aria-hidden="true" tabindex="-1"></a>plt.plot(train_steps, train_loss, label<span class="op">=</span><span class="st">"Training Loss"</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="5d3e4166-18"><a href="#5d3e4166-18" aria-hidden="true" tabindex="-1"></a>plt.plot(eval_steps, eval_loss, label<span class="op">=</span><span class="st">"Evaluation Loss"</span>, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="5d3e4166-19"><a href="#5d3e4166-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Training vs Evaluation Loss"</span>)</span>
<span id="5d3e4166-20"><a href="#5d3e4166-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Steps"</span>)</span>
<span id="5d3e4166-21"><a href="#5d3e4166-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="5d3e4166-22"><a href="#5d3e4166-22" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="5d3e4166-23"><a href="#5d3e4166-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="5d3e4166-24"><a href="#5d3e4166-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="5d3e4166-25"><a href="#5d3e4166-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The rapid decrease in training loss from approximately 3.5 to below 0.5 shows that the model’s parameters are being optimized effectively. The evaluation loss follows a similar downward trend and maintains a small gap relative to the training loss, which typically indicates strong generalization and the absence of severe overfitting. As both curves flatten out at a low loss level, the model appears to have reached a performance plateau, suggesting that additional training without further adjustments is unlikely to yield significant performance gains. Overall, these trends confirm that the fine-tuning process converged successfully.</p>
</section>
<section id="merging-adaptations-and-saving-the-model" class="level2">
<h2 class="anchored" data-anchor-id="merging-adaptations-and-saving-the-model">Merging adaptations and saving the model</h2>
<p>We explained previously that LoRA adds small, trainable “adapters” to the existing linear layers without modifying the core weights. To finalize the fine-tuning process, we need to merge these adaptations back into the main model weights. This step ensures that the model is self-contained and can be used independently without requiring the additional LoRA adapters.</p>
<p>We do that by saving the adapters <code>trainer.model.save_pretrained()</code>, and then by loading the model back with these adapters (<code>PeftModel.from_pretrained()</code>), and merging them back into the main model weights (<code>model.merge_and_unload()</code>). With a merged model, we can now save it for future use.</p>
<div id="64e962db" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="64e962db"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="64e962db-1"><a href="#64e962db-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> PeftModel</span>
<span id="64e962db-2"><a href="#64e962db-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="64e962db-3"><a href="#64e962db-3" aria-hidden="true" tabindex="-1"></a>trainer.model.save_pretrained(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/adapters"</span>)</span>
<span id="64e962db-4"><a href="#64e962db-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="64e962db-5"><a href="#64e962db-5" aria-hidden="true" tabindex="-1"></a>merged_model <span class="op">=</span> PeftModel.from_pretrained(</span>
<span id="64e962db-6"><a href="#64e962db-6" aria-hidden="true" tabindex="-1"></a>    model, <span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/adapters"</span></span>
<span id="64e962db-7"><a href="#64e962db-7" aria-hidden="true" tabindex="-1"></a>).merge_and_unload()</span>
<span id="64e962db-8"><a href="#64e962db-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="64e962db-9"><a href="#64e962db-9" aria-hidden="true" tabindex="-1"></a>merged_model.save_pretrained(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/model"</span>)</span>
<span id="64e962db-10"><a href="#64e962db-10" aria-hidden="true" tabindex="-1"></a>tokenizer.save_pretrained(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>('Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/tokenizer_config.json',
 'Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/special_tokens_map.json',
 'Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/vocab.json',
 'Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/merges.txt',
 'Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/added_tokens.json',
 'Qwen/Qwen2.5-0.5B-Instruct-finetuned/model/tokenizer.json')</code></pre>
</div>
</div>
</section>
<section id="testing-the-model" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-model">Testing the model</h2>
<p>Finally let us give the fine-tuned model a few prompts, and see if it performs as expected. We will use the <code>generate</code> method of the model to generate responses to the prompts. The method will return a list of generated responses, which we can then print out.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise suggestion
</div>
</div>
<div class="callout-body-container callout-body">
<p>As an exercise, you can try fine-tuning the model on a different dataset, or with a different model from the Hugging Face model hub. You can also try different LoRA configurations to see how they affect the fine-tuning process.</p>
</div>
</div>
<div id="9eea4b46" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="9eea4b46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="9eea4b46-1"><a href="#9eea4b46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prompt the model with a few arithmetic problems</span></span>
<span id="9eea4b46-2"><a href="#9eea4b46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-3"><a href="#9eea4b46-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="9eea4b46-4"><a href="#9eea4b46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-5"><a href="#9eea4b46-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/model"</span>)</span>
<span id="9eea4b46-6"><a href="#9eea4b46-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned/model"</span>)</span>
<span id="9eea4b46-7"><a href="#9eea4b46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-8"><a href="#9eea4b46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the correct pipeline type for causal LMs</span></span>
<span id="9eea4b46-9"><a href="#9eea4b46-9" aria-hidden="true" tabindex="-1"></a>arithmetic_solver <span class="op">=</span> pipeline(<span class="st">"text-generation"</span>, model<span class="op">=</span>model, tokenizer<span class="op">=</span>tokenizer)</span>
<span id="9eea4b46-10"><a href="#9eea4b46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-11"><a href="#9eea4b46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure generation properly</span></span>
<span id="9eea4b46-12"><a href="#9eea4b46-12" aria-hidden="true" tabindex="-1"></a>generation_config <span class="op">=</span> {</span>
<span id="9eea4b46-13"><a href="#9eea4b46-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_new_tokens"</span>: <span class="dv">100</span>,</span>
<span id="9eea4b46-14"><a href="#9eea4b46-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eos_token_id"</span>: tokenizer.eos_token_id,</span>
<span id="9eea4b46-15"><a href="#9eea4b46-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"early_stopping"</span>: <span class="va">True</span>,  <span class="co"># Stop if EOS is generated</span></span>
<span id="9eea4b46-16"><a href="#9eea4b46-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="9eea4b46-17"><a href="#9eea4b46-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-18"><a href="#9eea4b46-18" aria-hidden="true" tabindex="-1"></a>problems <span class="op">=</span> [</span>
<span id="9eea4b46-19"><a href="#9eea4b46-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Given x=12+3, solve for x."</span>,</span>
<span id="9eea4b46-20"><a href="#9eea4b46-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Given x=56*10, solve for x."</span>,</span>
<span id="9eea4b46-21"><a href="#9eea4b46-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"If x=10-4, what is x?"</span>,</span>
<span id="9eea4b46-22"><a href="#9eea4b46-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Solve for x, given x=3*4."</span>,</span>
<span id="9eea4b46-23"><a href="#9eea4b46-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"With x=13-3, x is what?"</span>,</span>
<span id="9eea4b46-24"><a href="#9eea4b46-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Given x=11*3, solve for x."</span>,</span>
<span id="9eea4b46-25"><a href="#9eea4b46-25" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="9eea4b46-26"><a href="#9eea4b46-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-27"><a href="#9eea4b46-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> problem <span class="kw">in</span> problems:</span>
<span id="9eea4b46-28"><a href="#9eea4b46-28" aria-hidden="true" tabindex="-1"></a>    messages <span class="op">=</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: problem}]</span>
<span id="9eea4b46-29"><a href="#9eea4b46-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-30"><a href="#9eea4b46-30" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> arithmetic_solver(messages, <span class="op">**</span>generation_config)</span>
<span id="9eea4b46-31"><a href="#9eea4b46-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="9eea4b46-32"><a href="#9eea4b46-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Prompt: </span><span class="sc">{</span>problem<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="9eea4b46-33"><a href="#9eea4b46-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Model: </span><span class="sc">{</span>result[<span class="dv">0</span>][<span class="st">'generated_text'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Prompt: Given x=12+3, solve for x.
Model: [{'role': 'user', 'content': 'Given x=12+3, solve for x.'}, {'role': 'assistant', 'content': 'x is 15'}]

Prompt: Given x=56*10, solve for x.
Model: [{'role': 'user', 'content': 'Given x=56*10, solve for x.'}, {'role': 'assistant', 'content': 'x is 560'}]

Prompt: If x=10-4, what is x?
Model: [{'role': 'user', 'content': 'If x=10-4, what is x?'}, {'role': 'assistant', 'content': 'x is 6'}]

Prompt: Solve for x, given x=3*4.
Model: [{'role': 'user', 'content': 'Solve for x, given x=3*4.'}, {'role': 'assistant', 'content': 'x is 12'}]

Prompt: With x=13-3, x is what?
Model: [{'role': 'user', 'content': 'With x=13-3, x is what?'}, {'role': 'assistant', 'content': 'x is 10'}]

Prompt: Given x=11*3, solve for x.
Model: [{'role': 'user', 'content': 'Given x=11*3, solve for x.'}, {'role': 'assistant', 'content': 'x is 33'}]
</code></pre>
</div>
</div>
<p>Yes! The model is generating the expected outputs, having generalized well from the training data. This is a good sign that the fine-tuning process was successful.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a></div></div></section></div></main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"state":{"051333cd9f50463e9df7e6607a49ed38":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"08ec5e8884b34ccca7afb3d9a8d2affc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b39597492658448d919f48f60dd1a4a8","placeholder":"​","style":"IPY_MODEL_9cbaca5e58fa4cc8bc12a1ae5a578b17","tabbable":null,"tooltip":null,"value":" 18000/18000 [00:00&lt;00:00, 22637.61 examples/s]"}},"0aaf46de9c094feebfb2b2d2b9d524c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_2b32ece35abe48b2ab18c33a8b482b4b","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a90fdf25c5ad465881bc538fed8c11dc","tabbable":null,"tooltip":null,"value":2000}},"0dea31277e234e4682e85bde0d7873f8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1043c47c89774ef08a6e5eb9d2db7fe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7d028933dfe24ae68b8717a4151c29ea","placeholder":"​","style":"IPY_MODEL_1452af496d3942acab260b8be978dfa6","tabbable":null,"tooltip":null,"value":"Applying chat template to eval dataset: 100%"}},"105d79d2ef1e4d16ba6cea4cd10dc9a8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1452af496d3942acab260b8be978dfa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"160ab7eaffad481c9bb345c23f32dc99":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1688c0b0334a40b38bef95d6101cc12a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17bef064cb27469fae6e58f2834136aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"19fabd72f5d240a3bfa0c72e12cb19c2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d08ef96bfb34339a560ef7021001829":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d62f98fd6a340d7ab03193c83c0baa8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"1f65bf4d22b043d6aa691295baa97ef4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"236397bb92fb40be9e3e11675da8d5cf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23a2a8a3bc364b72aff17b5c791861f3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a61bec59f54a289544eccc3e6955fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_757239e174e04c49b0ea732c84f31d55","placeholder":"​","style":"IPY_MODEL_3bee2bbdb7524b2b9797142c6c723dce","tabbable":null,"tooltip":null,"value":"Tokenizing eval dataset: 100%"}},"2619f777005b4db5a3b364d96891e5c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1043c47c89774ef08a6e5eb9d2db7fe6","IPY_MODEL_3ec4b052348a4e3f9d357a5a6a6b68ba","IPY_MODEL_84597f807abc4c54acf8629b42182d91"],"layout":"IPY_MODEL_d4930e33343443c8a73d8a32979b70a6","tabbable":null,"tooltip":null}},"2676600cd03b4993904af528fa04ece3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b32ece35abe48b2ab18c33a8b482b4b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bba19f5ff714d819cd1241e84358c48":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2d9bc2e4d6094ca298f5c30e5b4ee573":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e81cf8971164a128f74e2852e8065c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_79a33f2baa084566b02553154d2172ac","placeholder":"​","style":"IPY_MODEL_1d62f98fd6a340d7ab03193c83c0baa8","tabbable":null,"tooltip":null,"value":"Tokenizing train dataset: 100%"}},"3039972e14c3419b96647824bfb8b6ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25a61bec59f54a289544eccc3e6955fc","IPY_MODEL_6dc74c1fb5254dc0a9b9c04deb4b173b","IPY_MODEL_a1fb014e54c34a1a9961a952200c4356"],"layout":"IPY_MODEL_6ad10c2297e74c76a7ae5b74dd0d0ec7","tabbable":null,"tooltip":null}},"3b599161d5404486a4160c0f6004cd3e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bee2bbdb7524b2b9797142c6c723dce":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3ec4b052348a4e3f9d357a5a6a6b68ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_4afe8f6cd7564211a9890990ad7059a4","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bc020b9f64241d0ad2f6949f393e180","tabbable":null,"tooltip":null,"value":2000}},"40c6f4f2f9704464b8846150996ff01b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a6bb1efba5e94c528c6b1b101872c8ee","placeholder":"​","style":"IPY_MODEL_bcd0c2704b134719bac0cf4c7d79a97d","tabbable":null,"tooltip":null,"value":" 18000/18000 [00:01&lt;00:00, 9633.35 examples/s]"}},"4249bdf961964303b9cd1b4e6ab3867c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_aa30e6fbf8574e8ea81e36b2c1efcf80","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60d51911c6a14f0d902ee33842cd460e","tabbable":null,"tooltip":null,"value":18000}},"45185e491e084fc5a5723f3f19efa407":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_105d79d2ef1e4d16ba6cea4cd10dc9a8","placeholder":"​","style":"IPY_MODEL_1f65bf4d22b043d6aa691295baa97ef4","tabbable":null,"tooltip":null,"value":"Truncating eval dataset: 100%"}},"45aaeb4537b9431f9eb66cc659d6f6b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_66c6a6c7633a45ccb79e5bf397ffe6ff","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b246927281e44e35872706c7e74da175","tabbable":null,"tooltip":null,"value":18000}},"4afe8f6cd7564211a9890990ad7059a4":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7ce359a0bc4336aeecdcb2f8419841":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"512dd7222e934986877c32a6ecd9147a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8aa290b51b4698839bd59d31076ad5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a6f2455dac3b4682b9f061ce88edf7c0","placeholder":"​","style":"IPY_MODEL_ed9c6a10e57a469fbd100f4fc67ec32b","tabbable":null,"tooltip":null,"value":" 2000/2000 [00:00&lt;00:00, 22323.90 examples/s]"}},"5fdd81d599cf44bb847843c798183b00":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"609cec2c9d5f40849fbe5aa7ed9ed681":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa5373cd0853440484e4da81733f5c8e","IPY_MODEL_73f291d4fdf74dea8fb54d175239df4d","IPY_MODEL_962056b9f9d64f258f0ece69b56169a7"],"layout":"IPY_MODEL_2676600cd03b4993904af528fa04ece3","tabbable":null,"tooltip":null}},"60d51911c6a14f0d902ee33842cd460e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66c6a6c7633a45ccb79e5bf397ffe6ff":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad10c2297e74c76a7ae5b74dd0d0ec7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc74c1fb5254dc0a9b9c04deb4b173b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_84df54a0739a4df68aabd5a46361cb5c","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c04a7182919146dab11a5b68fc8b5a96","tabbable":null,"tooltip":null,"value":2000}},"7034e70f5d1a42909d546a7dd687b4f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_91cdfd8db062482198bf389c0ed529f5","placeholder":"​","style":"IPY_MODEL_2bba19f5ff714d819cd1241e84358c48","tabbable":null,"tooltip":null,"value":" 18000/18000 [00:00&lt;00:00, 25803.06 examples/s]"}},"73f291d4fdf74dea8fb54d175239df4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_da7bbfbe91eb458f86252d61bb8bf702","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c460c1e4bfa845b6951905a0c5b8e330","tabbable":null,"tooltip":null,"value":2000}},"757239e174e04c49b0ea732c84f31d55":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a33f2baa084566b02553154d2172ac":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d028933dfe24ae68b8717a4151c29ea":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de507ec958844b4b5353a42f2f98651":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45185e491e084fc5a5723f3f19efa407","IPY_MODEL_0aaf46de9c094feebfb2b2d2b9d524c0","IPY_MODEL_5a8aa290b51b4698839bd59d31076ad5"],"layout":"IPY_MODEL_1688c0b0334a40b38bef95d6101cc12a","tabbable":null,"tooltip":null}},"828e2c569f0c4b7d9c04d53ef1bb44f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4b7ce359a0bc4336aeecdcb2f8419841","placeholder":"​","style":"IPY_MODEL_8c4d88bc59c34d94a851ea211ba0e574","tabbable":null,"tooltip":null,"value":"Converting train dataset to ChatML: 100%"}},"84597f807abc4c54acf8629b42182d91":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1d08ef96bfb34339a560ef7021001829","placeholder":"​","style":"IPY_MODEL_051333cd9f50463e9df7e6607a49ed38","tabbable":null,"tooltip":null,"value":" 2000/2000 [00:00&lt;00:00, 21520.89 examples/s]"}},"84df54a0739a4df68aabd5a46361cb5c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b6aefc48c514b5e8b8a830eaa49c01e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e81cf8971164a128f74e2852e8065c7","IPY_MODEL_bc86b60328b94fa29ba19ed5bccd05d4","IPY_MODEL_40c6f4f2f9704464b8846150996ff01b"],"layout":"IPY_MODEL_b43cf396d83f4b7894e809d9f332c9a2","tabbable":null,"tooltip":null}},"8bc020b9f64241d0ad2f6949f393e180":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c4d88bc59c34d94a851ea211ba0e574":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"91cdfd8db062482198bf389c0ed529f5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962056b9f9d64f258f0ece69b56169a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0dea31277e234e4682e85bde0d7873f8","placeholder":"​","style":"IPY_MODEL_cbada9c60c924a03ae4c3a98d4d259bb","tabbable":null,"tooltip":null,"value":" 2000/2000 [00:00&lt;00:00, 36004.77 examples/s]"}},"99453fa1e6f54483bb5172aa5d18191e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb99a93125cd4a9e8c42d51d334a3c90","IPY_MODEL_b7cc709f96b84536af40d36a7dfc6e18","IPY_MODEL_08ec5e8884b34ccca7afb3d9a8d2affc"],"layout":"IPY_MODEL_bbdcbd2168c84292900077c77a644755","tabbable":null,"tooltip":null}},"9aa68db47f58439ba5b974a62a6bcf08":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cbaca5e58fa4cc8bc12a1ae5a578b17":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"9d6590ba787a43fb9807929851184813":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_828e2c569f0c4b7d9c04d53ef1bb44f2","IPY_MODEL_45aaeb4537b9431f9eb66cc659d6f6b8","IPY_MODEL_ea2e47a641284fa7b40a84a981bb2648"],"layout":"IPY_MODEL_23a2a8a3bc364b72aff17b5c791861f3","tabbable":null,"tooltip":null}},"a00ec66a00534758b1cd355e97a10a18":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fb014e54c34a1a9961a952200c4356":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_512dd7222e934986877c32a6ecd9147a","placeholder":"​","style":"IPY_MODEL_5fdd81d599cf44bb847843c798183b00","tabbable":null,"tooltip":null,"value":" 2000/2000 [00:00&lt;00:00, 9589.22 examples/s]"}},"a491651130964d0990441729b4ac5a0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6bb1efba5e94c528c6b1b101872c8ee":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f2455dac3b4682b9f061ce88edf7c0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a90fdf25c5ad465881bc538fed8c11dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa30e6fbf8574e8ea81e36b2c1efcf80":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac193aa1ef5248cd829eea84440fc996":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b246927281e44e35872706c7e74da175":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b39597492658448d919f48f60dd1a4a8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43cf396d83f4b7894e809d9f332c9a2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7cc709f96b84536af40d36a7dfc6e18":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3b599161d5404486a4160c0f6004cd3e","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a491651130964d0990441729b4ac5a0b","tabbable":null,"tooltip":null,"value":18000}},"bbdcbd2168c84292900077c77a644755":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc86b60328b94fa29ba19ed5bccd05d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_236397bb92fb40be9e3e11675da8d5cf","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5a37e7d8e514324853c36a99f2b2442","tabbable":null,"tooltip":null,"value":18000}},"bcd0c2704b134719bac0cf4c7d79a97d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"be98d821910942608255821ea6365859":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c04a7182919146dab11a5b68fc8b5a96":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c460c1e4bfa845b6951905a0c5b8e330":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4707b24db3a418a88a39d8fc1d6e207":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbff2c4342964226a56cd3036f340974","IPY_MODEL_4249bdf961964303b9cd1b4e6ab3867c","IPY_MODEL_7034e70f5d1a42909d546a7dd687b4f1"],"layout":"IPY_MODEL_19fabd72f5d240a3bfa0c72e12cb19c2","tabbable":null,"tooltip":null}},"cbada9c60c924a03ae4c3a98d4d259bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cbff2c4342964226a56cd3036f340974":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9aa68db47f58439ba5b974a62a6bcf08","placeholder":"​","style":"IPY_MODEL_be98d821910942608255821ea6365859","tabbable":null,"tooltip":null,"value":"Truncating train dataset: 100%"}},"d4930e33343443c8a73d8a32979b70a6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5a37e7d8e514324853c36a99f2b2442":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da7bbfbe91eb458f86252d61bb8bf702":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea2e47a641284fa7b40a84a981bb2648":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_160ab7eaffad481c9bb345c23f32dc99","placeholder":"​","style":"IPY_MODEL_f9a7d4ab1bc449c1a58780c261074d27","tabbable":null,"tooltip":null,"value":" 18000/18000 [00:00&lt;00:00, 40552.10 examples/s]"}},"eb99a93125cd4a9e8c42d51d334a3c90":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a00ec66a00534758b1cd355e97a10a18","placeholder":"​","style":"IPY_MODEL_ac193aa1ef5248cd829eea84440fc996","tabbable":null,"tooltip":null,"value":"Applying chat template to train dataset: 100%"}},"ed9c6a10e57a469fbd100f4fc67ec32b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f9a7d4ab1bc449c1a58780c261074d27":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fa5373cd0853440484e4da81733f5c8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2d9bc2e4d6094ca298f5c30e5b4ee573","placeholder":"​","style":"IPY_MODEL_17bef064cb27469fae6e58f2834136aa","tabbable":null,"tooltip":null,"value":"Converting eval dataset to ChatML: 100%"}}},"version_major":2,"version_minor":0}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/pedroleitao\.nl");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 Pedro Leitão</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with Quarto</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>